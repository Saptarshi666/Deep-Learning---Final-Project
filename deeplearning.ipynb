{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 502941,
     "status": "ok",
     "timestamp": 1729468538387,
     "user": {
      "displayName": "Saptarshi Mondal",
      "userId": "14698141573572217509"
     },
     "user_tz": 420
    },
    "id": "AGoYXULWTlUs",
    "outputId": "e159b064-8409-4a45-ca50-7c2b7841875c"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "# URL of the file\n",
    "url = \"http://immortal.multicomp.cs.cmu.edu/CMU-MOSEI/acoustic/CMU_MOSEI_COVAREP.csd\"\n",
    "\n",
    "# Local path where the file will be saved\n",
    "filename = \"CMU_MOSEI_COVAREP.csd\"\n",
    "\n",
    "# Download the file\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "print(f\"Downloaded {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2920,
     "status": "ok",
     "timestamp": 1729468541303,
     "user": {
      "displayName": "Saptarshi Mondal",
      "userId": "14698141573572217509"
     },
     "user_tz": 420
    },
    "id": "a7c7tqxHUK77",
    "outputId": "bc4199f9-388f-4133-c3c6-7a3f3d5d1666"
   },
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "\n",
    "# URL of the file\n",
    "url = \"http://immortal.multicomp.cs.cmu.edu/CMU-MOSEI/labels/CMU_MOSEI_Labels.csd\"\n",
    "\n",
    "# Local path where the file will be saved\n",
    "filename = \"CMU_MOSEI_Labels.csd\"\n",
    "\n",
    "# Download the file\n",
    "urllib.request.urlretrieve(url, filename)\n",
    "\n",
    "print(f\"Downloaded {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 905,
     "status": "ok",
     "timestamp": 1729469443577,
     "user": {
      "displayName": "Saptarshi Mondal",
      "userId": "14698141573572217509"
     },
     "user_tz": 420
    },
    "id": "cYHwV4hOYZDx",
    "outputId": "d5b0654a-9c01-49af-b145-805a80946c57"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deeps\\VSCodeProjects\\test\\CMU-MultimodalSDK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'CMU-MultimodalSDK' already exists and is not an empty directory.\n",
      "C:\\Users\\deeps\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "# Clone the CMU-MultimodalSDK repository\n",
    "!git clone https://github.com/CMU-MultiComp-Lab/CMU-MultimodalSDK.git\n",
    "\n",
    "# Navigate to the cloned repository\n",
    "%cd CMU-MultimodalSDK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4105,
     "status": "ok",
     "timestamp": 1729469447680,
     "user": {
      "displayName": "Saptarshi Mondal",
      "userId": "14698141573572217509"
     },
     "user_tz": 420
    },
    "id": "KlYQRGmFbNQe",
    "outputId": "bfb756fb-a593-4257-cac6-4456c62ca4e2"
   },
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4287,
     "status": "ok",
     "timestamp": 1729469451962,
     "user": {
      "displayName": "Saptarshi Mondal",
      "userId": "14698141573572217509"
     },
     "user_tz": 420
    },
    "id": "sTLYtdYDbR6M",
    "outputId": "060e5b92-c6fa-4812-e3dc-59d642f50eae"
   },
   "outputs": [],
   "source": [
    "%pip install numpy h5py pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install requests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deeps\\VSCodeProjects\\test\\CMU-MultimodalSDK\\CMU-MultimodalSDK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deeps\\AppData\\Roaming\\Python\\Python312\\site-packages\\IPython\\core\\magics\\osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd CMU-MultimodalSDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 48626,
     "status": "ok",
     "timestamp": 1729469500586,
     "user": {
      "displayName": "Saptarshi Mondal",
      "userId": "14698141573572217509"
     },
     "user_tz": 420
    },
    "id": "4voJONolbUVw",
    "outputId": "1f1e877c-02c3-4185-f772-ddc67dc63db3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deeps\\VSCodeProjects\\test\\CMU-MultimodalSDK\\CMU-MultimodalSDK\\mmsdk\\mmdatasdk\\log\\log.py:105: SyntaxWarning: invalid escape sequence '\\|'\n",
      "  status (\"%s%s\"%(message,'/-\\|'[int(progress*speed)%4]),end=\"\\r\")\n",
      "c:\\Users\\deeps\\VSCodeProjects\\test\\CMU-MultimodalSDK\\CMU-MultimodalSDK\\mmsdk\\mmdatasdk\\computational_sequence\\file_ops.py:53: SyntaxWarning: \"is\" with 'int' literal. Did you mean \"==\"?\n",
      "  metadataHandle.create_dataset(metadataKey,(1,),dtype=h5py.special_dtype(vlen=unicode) if sys.version_info.major is 2 else h5py.special_dtype(vlen=str))\n",
      "c:\\Users\\deeps\\VSCodeProjects\\test\\CMU-MultimodalSDK\\CMU-MultimodalSDK\\mmsdk\\mmdatasdk\\computational_sequence\\file_ops.py:54: SyntaxWarning: \"is\" with 'int' literal. Did you mean \"==\"?\n",
      "  cast_operator=unicode if sys.version_info.major is 2 else str\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-10-22 04:40:14.198] | Success | \u001b[0mComputational sequence read from file C:\\Users\\deeps\\VSCodeProjects\\test\\CMU-MultimodalSDK\\CMU_MOSEI_COVAREP.csd ...\n",
      "\u001b[94m\u001b[1m[2024-10-22 04:40:14.875] | Status  | \u001b[0mChecking the integrity of the <COVAREP> computational sequence ...\n",
      "\u001b[94m\u001b[1m[2024-10-22 04:40:14.875] | Status  | \u001b[0mChecking the format of the data in <COVAREP> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-10-22 04:40:17.012] | Success | \u001b[0m<COVAREP> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2024-10-22 04:40:17.012] | Status  | \u001b[0mChecking the format of the metadata in <COVAREP> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2024-10-22 04:40:17.012] | Warning | \u001b[0m<COVAREP> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2024-10-22 04:40:17.021] | Success | \u001b[0mComputational sequence read from file C:\\Users\\deeps\\VSCodeProjects\\test\\CMU-MultimodalSDK\\CMU_MOSEI_Labels.csd ...\n",
      "\u001b[94m\u001b[1m[2024-10-22 04:40:17.618] | Status  | \u001b[0mChecking the integrity of the <All Labels> computational sequence ...\n",
      "\u001b[94m\u001b[1m[2024-10-22 04:40:17.618] | Status  | \u001b[0mChecking the format of the data in <All Labels> computational sequence ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[92m\u001b[1m[2024-10-22 04:40:18.917] | Success | \u001b[0m<All Labels> computational sequence data in correct format.\n",
      "\u001b[94m\u001b[1m[2024-10-22 04:40:18.917] | Status  | \u001b[0mChecking the format of the metadata in <All Labels> computational sequence ...\n",
      "\u001b[93m\u001b[1m[2024-10-22 04:40:18.917] | Warning | \u001b[0m<All Labels> computational sequence does not have all the required metadata ... continuing \n",
      "\u001b[92m\u001b[1m[2024-10-22 04:40:18.917] | Success | \u001b[0mDataset initialized successfully ... \n",
      "dict_keys(['COVAREP', 'Labels'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import requests\n",
    "sys.path.append('/content/CMU-MultimodalSDK')\n",
    "\n",
    "from mmsdk import mmdatasdk\n",
    "\n",
    "# Define the paths to your .csd files\n",
    "data_paths = {\n",
    "    'COVAREP': r'C:\\Users\\deeps\\VSCodeProjects\\test\\CMU-MultimodalSDK\\CMU_MOSEI_COVAREP.csd',\n",
    "    'Labels': r'C:\\Users\\deeps\\VSCodeProjects\\test\\CMU-MultimodalSDK\\CMU_MOSEI_Labels.csd',\n",
    "}\n",
    "\n",
    "# Load the dataset using the SDK\n",
    "dataset = mmdatasdk.mmdataset(data_paths)\n",
    "\n",
    "# Check the keys in the loaded dataset\n",
    "print(dataset.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 33,
     "status": "ok",
     "timestamp": 1729469500586,
     "user": {
      "displayName": "Saptarshi Mondal",
      "userId": "14698141573572217509"
     },
     "user_tz": 420
    },
    "id": "FdJDo7CcUq5n"
   },
   "outputs": [],
   "source": [
    "covarep_metadata = dataset['COVAREP'].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 32,
     "status": "ok",
     "timestamp": 1729469500587,
     "user": {
      "displayName": "Saptarshi Mondal",
      "userId": "14698141573572217509"
     },
     "user_tz": 420
    },
    "id": "BE-G1tbcBISy",
    "outputId": "5de11c93-1b57-4f53-d9d4-7a29f83f597d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COVAREP key-value pairs:\n",
      "Video ID: --qXJuDtHPw\n",
      "Timestamps: <HDF5 dataset \"intervals\": shape (5721, 2), type \"<f8\">\n",
      "Features: <HDF5 dataset \"features\": shape (5721, 74), type \"<f4\">\n",
      "\n",
      "Video ID: -3g5yACwYnA\n",
      "Timestamps: <HDF5 dataset \"intervals\": shape (14475, 2), type \"<f8\">\n",
      "Features: <HDF5 dataset \"features\": shape (14475, 74), type \"<f4\">\n",
      "\n",
      "Labels key-value pairs:\n",
      "Video ID: --qXJuDtHPw\n",
      "Timestamps: <HDF5 dataset \"intervals\": shape (1, 2), type \"<f8\">\n",
      "Labels: <HDF5 dataset \"features\": shape (1, 7), type \"<f4\">\n",
      "\n",
      "Video ID: -3g5yACwYnA\n",
      "Timestamps: <HDF5 dataset \"intervals\": shape (6, 2), type \"<f8\">\n",
      "Labels: <HDF5 dataset \"features\": shape (6, 7), type \"<f4\">\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Access the COVAREP and Labels data\n",
    "covarep_data = dataset['COVAREP'].data\n",
    "labels_data = dataset['Labels'].data\n",
    "\n",
    "# Explore COVAREP data: print out a few key-value pairs\n",
    "print(\"COVAREP key-value pairs:\")\n",
    "for video_id, covarep_info in list(covarep_data.items())[:2]:  # limiting to first 2 videos for brevity\n",
    "    print(f\"Video ID: {video_id}\")\n",
    "    print(f\"Timestamps: {covarep_info['intervals']}\")\n",
    "    print(f\"Features: {covarep_info['features']}\\n\")  # COVAREP features (e.g., pitch, voice quality)\n",
    "\n",
    "# Explore Labels data: print out a few key-value pairs\n",
    "print(\"Labels key-value pairs:\")\n",
    "for video_id, label_info in list(labels_data.items())[:2]:  # limiting to first 2 videos for brevity\n",
    "    print(f\"Video ID: {video_id}\")\n",
    "    print(f\"Timestamps: {label_info['intervals']}\")\n",
    "    print(f\"Labels: {label_info['features']}\\n\")  # sentiment or emotion labels for each segment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.2.3)\n",
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (2.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\deeps\\appdata\\roaming\\python\\python312\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas) (2024.2)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\deeps\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading scikit_learn-1.5.2-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "   ---------------------------------------- 0.0/11.0 MB ? eta -:--:--\n",
      "   -------------------- ------------------- 5.8/11.0 MB 32.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 9.4/11.0 MB 30.9 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.0/11.0 MB 22.9 MB/s eta 0:00:00\n",
      "Downloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "Downloading scipy-1.14.1-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "   ---------------------------------------- 0.0/44.5 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 6.3/44.5 MB 35.1 MB/s eta 0:00:02\n",
      "   ---------- ----------------------------- 11.5/44.5 MB 30.1 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 18.6/44.5 MB 30.9 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 25.2/44.5 MB 31.2 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 32.5/44.5 MB 32.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 39.8/44.5 MB 32.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.3/44.5 MB 32.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  44.3/44.5 MB 32.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 44.5/44.5 MB 27.0 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.2 scipy-1.14.1 threadpoolctl-3.5.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas scikit-learn numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "LZCqfKc3PIh0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ARE WE HERE\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'covarep_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m max_records_per_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1_000_000\u001b[39m  \u001b[38;5;66;03m# Maximum records to store in each CSV file\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Iterate through the video IDs that are present in both COVAREP and Labels datasets\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m video_id \u001b[38;5;129;01min\u001b[39;00m \u001b[43mcovarep_data\u001b[49m\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m     12\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTHIS IS MY FIRST LOOP\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m video_id \u001b[38;5;129;01min\u001b[39;00m labels_data:\n\u001b[0;32m     14\u001b[0m         \u001b[38;5;66;03m# Get the COVAREP data (features and timestamps)\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'covarep_data' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"ARE WE HERE\")\n",
    "# Initialize a list to store all concatenated rows\n",
    "all_concatenated_rows = []\n",
    "output_file_index = 0\n",
    "max_records_per_file = 1_000_000  # Maximum records to store in each CSV file\n",
    "\n",
    "# Iterate through the video IDs that are present in both COVAREP and Labels datasets\n",
    "for video_id in covarep_data.keys():\n",
    "    print(\"THIS IS MY FIRST LOOP\")\n",
    "    if video_id in labels_data:\n",
    "        # Get the COVAREP data (features and timestamps)\n",
    "        covarep_features = np.array(covarep_data[video_id]['features'])\n",
    "        covarep_timestamps = np.array(covarep_data[video_id]['intervals'])\n",
    "\n",
    "        # Create column headers after retrieving covarep_features\n",
    "        covarep_column_names = [f'covarep_feature_{i}' for i in range(covarep_features.shape[1])]\n",
    "        \n",
    "        # Get the Labels data (features and timestamps)\n",
    "        label_features = np.array(labels_data[video_id]['features'])\n",
    "        label_timestamps = np.array(labels_data[video_id]['intervals'])\n",
    "\n",
    "        # Convert label_timestamps and label_features to lists for easier manipulation\n",
    "        label_timestamps = label_timestamps.tolist()\n",
    "        label_features = label_features.tolist()\n",
    "\n",
    "        # Loop through COVAREP intervals and match with exact label intervals\n",
    "        for i, covarep_interval in enumerate(covarep_timestamps):\n",
    "            print(\"THIS IS MY SECOND LOOP\")\n",
    "            # Find the corresponding label interval and feature\n",
    "            for j, label_interval in enumerate(label_timestamps):\n",
    "                if covarep_interval[0] >= label_interval[0] and covarep_interval[1] <= label_interval[1]:\n",
    "                    # Concatenate COVAREP features with labels for matching intervals\n",
    "                    concatenated_row = np.concatenate((covarep_features[i], label_features[j]))\n",
    "\n",
    "                    # Add video_id and interval to the concatenated row for tracking\n",
    "                    concatenated_row_with_id = np.concatenate(([video_id], concatenated_row))\n",
    "\n",
    "                    # Append the row to the final dataset list\n",
    "                    all_concatenated_rows.append(concatenated_row_with_id)\n",
    "\n",
    "                    # Check if we have reached the maximum records for a CSV file\n",
    "                    if len(all_concatenated_rows) >= max_records_per_file:\n",
    "                        # Create a DataFrame from the collected rows\n",
    "                        label_column_names = ['Sentiment', 'Happy', 'Sad', 'Anger', 'Surprise', 'Disgust', 'Fear']\n",
    "                        columns = ['video_id'] + covarep_column_names + label_column_names\n",
    "                        df = pd.DataFrame(all_concatenated_rows, columns=columns)\n",
    "\n",
    "                        # Save the DataFrame to a CSV file\n",
    "                        output_file_name = f'concatenated_features_labels_{output_file_index}.csv'\n",
    "                        df.to_csv(output_file_name, index=False)\n",
    "                        print(f\"Concatenated data written to {output_file_name}\")\n",
    "\n",
    "                        # Increment the output file index and clear the rows for the next file\n",
    "                        output_file_index += 1\n",
    "                        all_concatenated_rows.clear()  # Clear the list for the next batch\n",
    "\n",
    "                    break  # Move to the next COVAREP interval once a match is found\n",
    "\n",
    "# Save any remaining rows to a final CSV file if not empty\n",
    "if all_concatenated_rows:\n",
    "    label_column_names = ['Sentiment', 'Happy', 'Sad', 'Anger', 'Surprise', 'Disgust', 'Fear']\n",
    "    columns = ['video_id'] + covarep_column_names + label_column_names\n",
    "    df = pd.DataFrame(all_concatenated_rows, columns=columns)\n",
    "    output_file_name = f'concatenated_features_labels_{output_file_index}.csv'\n",
    "    df.to_csv(output_file_name, index=False)\n",
    "    print(f\"Concatenated data written to {output_file_name}\")\n",
    "\n",
    "print(\"Data processing completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboostNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script wheel.exe is installed in 'c:\\Users\\deeps\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts f2py.exe and numpy-config.exe are installed in 'c:\\Users\\deeps\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown_py.exe is installed in 'c:\\Users\\deeps\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script markdown-it.exe is installed in 'c:\\Users\\deeps\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The script tensorboard.exe is installed in 'c:\\Users\\deeps\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe, toco.exe and toco_from_protos.exe are installed in 'c:\\Users\\deeps\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Downloading xgboost-2.1.2-py3-none-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl.metadata (3.3 kB)\n",
      "Requirement already satisfied: numpy in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (2.1.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from xgboost) (1.14.1)\n",
      "Collecting tensorflow-intel==2.18.0 (from tensorflow)\n",
      "  Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl.metadata (4.9 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\users\\deeps\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (24.1)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (2.32.3)\n",
      "Collecting setuptools (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading setuptools-75.3.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\deeps\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading termcolor-2.5.0-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting typing-extensions>=3.6.6 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading grpcio-1.67.1-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard<2.19,>=2.18 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading keras-3.6.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting numpy (from xgboost)\n",
      "  Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl.metadata (59 kB)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from tensorflow-intel==2.18.0->tensorflow) (3.12.1)\n",
      "Collecting ml-dtypes<0.5.0,>=0.4.0 (from tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl.metadata (20 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading wheel-0.44.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading rich-13.9.3-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading namex-0.0.8-py3-none-any.whl.metadata (246 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading optree-0.13.0-cp312-cp312-win_amd64.whl.metadata (48 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow-intel==2.18.0->tensorflow) (2024.8.30)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading Markdown-3.7-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading werkzeug-3.0.6-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting MarkupSafe>=2.1.1 (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading markdown_it_py-3.0.0-py3-none-any.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\deeps\\appdata\\roaming\\python\\python312\\site-packages (from rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow) (2.18.0)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow-intel==2.18.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading xgboost-2.1.2-py3-none-win_amd64.whl (124.9 MB)\n",
      "   ---------------------------------------- 0.0/124.9 MB ? eta -:--:--\n",
      "   - -------------------------------------- 6.0/124.9 MB 30.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 13.1/124.9 MB 32.9 MB/s eta 0:00:04\n",
      "   ------ --------------------------------- 20.2/124.9 MB 32.7 MB/s eta 0:00:04\n",
      "   -------- ------------------------------- 27.0/124.9 MB 32.9 MB/s eta 0:00:03\n",
      "   ---------- ----------------------------- 34.1/124.9 MB 33.3 MB/s eta 0:00:03\n",
      "   ------------- -------------------------- 41.2/124.9 MB 33.5 MB/s eta 0:00:03\n",
      "   --------------- ------------------------ 48.2/124.9 MB 33.4 MB/s eta 0:00:03\n",
      "   ----------------- ---------------------- 55.3/124.9 MB 33.5 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 61.9/124.9 MB 33.4 MB/s eta 0:00:02\n",
      "   --------------------- ------------------ 68.7/124.9 MB 33.4 MB/s eta 0:00:02\n",
      "   ------------------------ --------------- 75.8/124.9 MB 33.6 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 82.8/124.9 MB 33.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 89.7/124.9 MB 33.8 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 97.0/124.9 MB 33.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------ 104.1/124.9 MB 33.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ---- 111.1/124.9 MB 33.8 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 118.0/124.9 MB 33.8 MB/s eta 0:00:01\n",
      "   --------------------------------------  124.8/124.9 MB 33.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 124.9/124.9 MB 32.7 MB/s eta 0:00:00\n",
      "Downloading tensorflow-2.18.0-cp312-cp312-win_amd64.whl (7.5 kB)\n",
      "Downloading tensorflow_intel-2.18.0-cp312-cp312-win_amd64.whl (390.3 MB)\n",
      "   ---------------------------------------- 0.0/390.3 MB ? eta -:--:--\n",
      "    --------------------------------------- 6.6/390.3 MB 33.6 MB/s eta 0:00:12\n",
      "   - -------------------------------------- 13.9/390.3 MB 33.6 MB/s eta 0:00:12\n",
      "   -- ------------------------------------- 21.0/390.3 MB 34.0 MB/s eta 0:00:11\n",
      "   -- ------------------------------------- 28.3/390.3 MB 34.5 MB/s eta 0:00:11\n",
      "   --- ------------------------------------ 35.7/390.3 MB 34.3 MB/s eta 0:00:11\n",
      "   ---- ----------------------------------- 42.5/390.3 MB 34.2 MB/s eta 0:00:11\n",
      "   ----- ---------------------------------- 49.8/390.3 MB 34.5 MB/s eta 0:00:10\n",
      "   ----- ---------------------------------- 56.6/390.3 MB 34.0 MB/s eta 0:00:10\n",
      "   ------ --------------------------------- 63.7/390.3 MB 34.1 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 70.3/390.3 MB 34.2 MB/s eta 0:00:10\n",
      "   ------- -------------------------------- 77.1/390.3 MB 33.9 MB/s eta 0:00:10\n",
      "   -------- ------------------------------- 84.7/390.3 MB 34.2 MB/s eta 0:00:09\n",
      "   --------- ------------------------------ 92.0/390.3 MB 34.1 MB/s eta 0:00:09\n",
      "   ---------- ----------------------------- 98.8/390.3 MB 34.1 MB/s eta 0:00:09\n",
      "   ---------- ---------------------------- 105.6/390.3 MB 34.1 MB/s eta 0:00:09\n",
      "   ----------- --------------------------- 112.7/390.3 MB 34.1 MB/s eta 0:00:09\n",
      "   ----------- --------------------------- 119.8/390.3 MB 34.2 MB/s eta 0:00:08\n",
      "   ------------ -------------------------- 126.9/390.3 MB 34.0 MB/s eta 0:00:08\n",
      "   ------------- ------------------------- 134.0/390.3 MB 34.1 MB/s eta 0:00:08\n",
      "   -------------- ------------------------ 141.0/390.3 MB 34.1 MB/s eta 0:00:08\n",
      "   -------------- ------------------------ 148.4/390.3 MB 34.1 MB/s eta 0:00:08\n",
      "   --------------- ----------------------- 155.7/390.3 MB 34.2 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 162.8/390.3 MB 34.1 MB/s eta 0:00:07\n",
      "   ---------------- ---------------------- 169.3/390.3 MB 34.0 MB/s eta 0:00:07\n",
      "   ----------------- --------------------- 176.4/390.3 MB 34.1 MB/s eta 0:00:07\n",
      "   ------------------ -------------------- 183.5/390.3 MB 34.0 MB/s eta 0:00:07\n",
      "   ------------------- ------------------- 190.3/390.3 MB 34.0 MB/s eta 0:00:06\n",
      "   ------------------- ------------------- 197.4/390.3 MB 34.0 MB/s eta 0:00:06\n",
      "   -------------------- ------------------ 204.5/390.3 MB 34.0 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 211.6/390.3 MB 34.0 MB/s eta 0:00:06\n",
      "   --------------------- ----------------- 218.6/390.3 MB 34.0 MB/s eta 0:00:06\n",
      "   ---------------------- ---------------- 225.4/390.3 MB 34.0 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 232.5/390.3 MB 34.0 MB/s eta 0:00:05\n",
      "   ----------------------- --------------- 239.6/390.3 MB 34.0 MB/s eta 0:00:05\n",
      "   ------------------------ -------------- 246.7/390.3 MB 34.1 MB/s eta 0:00:05\n",
      "   ------------------------- ------------- 254.0/390.3 MB 34.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 261.6/390.3 MB 34.1 MB/s eta 0:00:04\n",
      "   -------------------------- ------------ 269.0/390.3 MB 34.1 MB/s eta 0:00:04\n",
      "   --------------------------- ----------- 276.3/390.3 MB 34.1 MB/s eta 0:00:04\n",
      "   ---------------------------- ---------- 283.4/390.3 MB 34.1 MB/s eta 0:00:04\n",
      "   ----------------------------- --------- 290.5/390.3 MB 34.1 MB/s eta 0:00:03\n",
      "   ----------------------------- --------- 297.3/390.3 MB 34.1 MB/s eta 0:00:03\n",
      "   ------------------------------ -------- 304.3/390.3 MB 34.1 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 310.6/390.3 MB 33.9 MB/s eta 0:00:03\n",
      "   ------------------------------- ------- 318.0/390.3 MB 34.1 MB/s eta 0:00:03\n",
      "   -------------------------------- ------ 324.8/390.3 MB 34.1 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 331.6/390.3 MB 34.0 MB/s eta 0:00:02\n",
      "   --------------------------------- ----- 338.4/390.3 MB 34.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ---- 345.5/390.3 MB 34.0 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 352.3/390.3 MB 33.9 MB/s eta 0:00:02\n",
      "   ----------------------------------- --- 359.1/390.3 MB 33.9 MB/s eta 0:00:01\n",
      "   ------------------------------------ -- 366.2/390.3 MB 33.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 373.0/390.3 MB 33.9 MB/s eta 0:00:01\n",
      "   ------------------------------------- - 380.1/390.3 MB 33.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  387.7/390.3 MB 33.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 33.9 MB/s eta 0:00:01\n",
      "   --------------------------------------  390.1/390.3 MB 33.9 MB/s eta 0:00:01\n",
      "   --------------------------------------- 390.3/390.3 MB 32.5 MB/s eta 0:00:00\n",
      "Downloading numpy-2.0.2-cp312-cp312-win_amd64.whl (15.6 MB)\n",
      "   ---------------------------------------- 0.0/15.6 MB ? eta -:--:--\n",
      "   ------------------ --------------------- 7.1/15.6 MB 36.4 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 13.9/15.6 MB 33.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.6/15.6 MB 32.8 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.67.1-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 4.3/4.3 MB 32.7 MB/s eta 0:00:00\n",
      "Downloading keras-3.6.0-py3-none-any.whl (1.2 MB)\n",
      "   ---------------------------------------- 0.0/1.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.2/1.2 MB 30.0 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   ---------- ----------------------------- 7.1/26.4 MB 33.6 MB/s eta 0:00:01\n",
      "   --------------------- ------------------ 14.4/26.4 MB 34.9 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 21.2/26.4 MB 34.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 32.8 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.4.1-cp312-cp312-win_amd64.whl (127 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-5.28.3-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Downloading tensorboard-2.18.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 5.5/5.5 MB 30.5 MB/s eta 0:00:00\n",
      "Downloading setuptools-75.3.0-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 30.9 MB/s eta 0:00:00\n",
      "Downloading termcolor-2.5.0-py3-none-any.whl (7.8 kB)\n",
      "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Downloading wrapt-1.16.0-cp312-cp312-win_amd64.whl (37 kB)\n",
      "Downloading Markdown-3.7-py3-none-any.whl (106 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading werkzeug-3.0.6-py3-none-any.whl (227 kB)\n",
      "Downloading wheel-0.44.0-py3-none-any.whl (67 kB)\n",
      "Downloading namex-0.0.8-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.13.0-cp312-cp312-win_amd64.whl (283 kB)\n",
      "Downloading rich-13.9.3-py3-none-any.whl (242 kB)\n",
      "Downloading markdown_it_py-3.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading MarkupSafe-3.0.2-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, typing-extensions, termcolor, tensorboard-data-server, setuptools, protobuf, opt-einsum, numpy, mdurl, MarkupSafe, markdown, grpcio, google-pasta, gast, absl-py, werkzeug, optree, ml-dtypes, markdown-it-py, astunparse, xgboost, tensorboard, rich, keras, tensorflow-intel, tensorflow\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.1.2\n",
      "    Uninstalling numpy-2.1.2:\n",
      "      Successfully uninstalled numpy-2.1.2\n",
      "Successfully installed MarkupSafe-3.0.2 absl-py-2.1.0 astunparse-1.6.3 flatbuffers-24.3.25 gast-0.6.0 google-pasta-0.2.0 grpcio-1.67.1 keras-3.6.0 libclang-18.1.1 markdown-3.7 markdown-it-py-3.0.0 mdurl-0.1.2 ml-dtypes-0.4.1 namex-0.0.8 numpy-2.0.2 opt-einsum-3.4.0 optree-0.13.0 protobuf-5.28.3 rich-13.9.3 setuptools-75.3.0 tensorboard-2.18.0 tensorboard-data-server-0.7.2 tensorflow-2.18.0 tensorflow-intel-2.18.0 termcolor-2.5.0 typing-extensions-4.12.2 werkzeug-3.0.6 wheel-0.44.0 wrapt-1.16.0 xgboost-2.1.2\n"
     ]
    }
   ],
   "source": [
    "%pip install xgboost tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\deeps\\AppData\\Local\\Temp\\ipykernel_3468\\82723410.py:10: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file)\n",
      "C:\\Users\\deeps\\AppData\\Local\\Temp\\ipykernel_3468\\82723410.py:10: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file)\n",
      "C:\\Users\\deeps\\AppData\\Local\\Temp\\ipykernel_3468\\82723410.py:10: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file)\n",
      "C:\\Users\\deeps\\AppData\\Local\\Temp\\ipykernel_3468\\82723410.py:10: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file)\n",
      "C:\\Users\\deeps\\AppData\\Local\\Temp\\ipykernel_3468\\82723410.py:10: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file)\n",
      "C:\\Users\\deeps\\AppData\\Local\\Temp\\ipykernel_3468\\82723410.py:10: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file)\n",
      "C:\\Users\\deeps\\AppData\\Local\\Temp\\ipykernel_3468\\82723410.py:10: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid values detected in features. Cleaning data...\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import glob\n",
    "\n",
    "# Function to load data from a single CSV file\n",
    "def load_and_preprocess(file):\n",
    "    data = pd.read_csv(file)\n",
    "    # Drop the first column and separate features and outputs\n",
    "    data = data.iloc[:, 1:]  # Drop the first column\n",
    "    X = data.iloc[:, :74]     # Features\n",
    "    y = data.iloc[:, 74:]      # First output\n",
    "    return X, y\n",
    "\n",
    "# Initialize empty lists for features and outputs\n",
    "X_all = []\n",
    "y_all = []\n",
    "\n",
    "# Load and preprocess each CSV file\n",
    "file_pattern = 'C:\\\\Users\\\\deeps\\\\VSCodeProjects\\\\test\\\\*.csv'  # Update this path\n",
    "for filename in glob.glob(file_pattern):\n",
    "    X, y = load_and_preprocess(filename)\n",
    "    X_all.append(X)\n",
    "    y_all.append(y)\n",
    "\n",
    "# Concatenate the data from all files\n",
    "X_combined = pd.concat(X_all, ignore_index=True)\n",
    "y_combined = pd.concat(y_all, ignore_index=True)\n",
    "\n",
    "# Sample only 20% of the combined dataset\n",
    "X_combined = X_combined.sample(frac=0.1, random_state=42)\n",
    "y_combined = y_combined.loc[X_combined.index]  # Align target with sampled features\n",
    "\n",
    "# Check for NaN or infinite values in the features\n",
    "if np.any(np.isnan(X_combined)) or np.any(np.isinf(X_combined)):\n",
    "    print(\"Invalid values detected in features. Cleaning data...\")\n",
    "    \n",
    "    # Drop rows with invalid values\n",
    "    X_combined = X_combined.dropna().replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    y_combined = y_combined.loc[X_combined.index]  # Align target with features\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          covarep_feature_0  covarep_feature_1  covarep_feature_2  \\\n",
      "5612632               158.5                1.0           0.124120   \n",
      "14956465              145.0                0.0           0.001993   \n",
      "4501974               112.0                1.0           0.171363   \n",
      "10795064              136.5                1.0           0.042043   \n",
      "8151270                 1.0                0.0           0.000000   \n",
      "...                     ...                ...                ...   \n",
      "1256776               171.0                1.0           0.179577   \n",
      "8239048               124.5                1.0           0.085250   \n",
      "16013432              228.5                0.0           0.035823   \n",
      "3959756               212.0                1.0           0.036027   \n",
      "3858492               152.5                1.0           0.082501   \n",
      "\n",
      "          covarep_feature_3  covarep_feature_4  covarep_feature_5  \\\n",
      "5612632            0.696494           3.214920           0.424664   \n",
      "14956465           0.009145          -1.340461           0.071229   \n",
      "4501974            0.503045          13.868276           0.262442   \n",
      "10795064           0.128102          -8.162551           1.193772   \n",
      "8151270            0.000000           0.000000           0.000000   \n",
      "...                     ...                ...                ...   \n",
      "1256776            0.388322           6.731714           0.188754   \n",
      "8239048            0.719132          -2.465057           0.385272   \n",
      "16013432           0.140568           2.716115           0.081890   \n",
      "3959756            0.104458          15.776600           0.346703   \n",
      "3858492            0.426729          10.168280           0.300564   \n",
      "\n",
      "          covarep_feature_6  covarep_feature_7  covarep_feature_8  \\\n",
      "5612632            0.110436          -0.294661           2.068004   \n",
      "14956465           0.107564          -0.046403           0.992245   \n",
      "4501974            0.158395          -0.395950           0.547856   \n",
      "10795064           0.131462          -0.267432           0.909359   \n",
      "8151270            0.000000          -0.046154           0.000000   \n",
      "...                     ...                ...                ...   \n",
      "1256776            0.159816          -0.217649           2.037023   \n",
      "8239048            0.118702          -0.335780           2.489501   \n",
      "16013432           0.135744          -0.202367           1.785532   \n",
      "3959756            0.111837          -0.257604           1.748205   \n",
      "3858492            0.131331          -0.417764           1.140180   \n",
      "\n",
      "          covarep_feature_9  ...  covarep_feature_64  covarep_feature_65  \\\n",
      "5612632            0.821100  ...           -1.058739           -0.866026   \n",
      "14956465           0.465621  ...           -0.755451           -0.711942   \n",
      "4501974            0.330625  ...           -0.885012           -0.802911   \n",
      "10795064           0.406819  ...           -1.057514           -0.866024   \n",
      "8151270            0.000000  ...            0.000000            0.000000   \n",
      "...                     ...  ...                 ...                 ...   \n",
      "1256776            0.368700  ...           -1.109304           -1.039754   \n",
      "8239048            0.685425  ...           -0.844784           -0.816730   \n",
      "16013432           0.479824  ...           -1.231407           -1.002016   \n",
      "3959756            0.348640  ...           -1.312841           -1.043882   \n",
      "3858492            0.283795  ...           -0.825530           -0.739081   \n",
      "\n",
      "          covarep_feature_66  covarep_feature_67  covarep_feature_68  \\\n",
      "5612632            -0.783809           -0.667262           -0.445418   \n",
      "14956465           -0.604483           -0.559642           -0.555230   \n",
      "4501974            -0.730399           -0.712205           -0.572361   \n",
      "10795064           -0.714476           -0.633587           -0.535941   \n",
      "8151270             0.000000            0.000000            0.000000   \n",
      "...                      ...                 ...                 ...   \n",
      "1256776            -0.905157           -0.667322           -0.540923   \n",
      "8239048            -0.575114           -0.621790           -0.434569   \n",
      "16013432           -0.789726           -0.698616           -0.591020   \n",
      "3959756            -0.542651           -0.606155           -0.014638   \n",
      "3858492            -0.639446           -0.624436           -0.472783   \n",
      "\n",
      "          covarep_feature_69  covarep_feature_70  covarep_feature_71  \\\n",
      "5612632            -0.406686           -0.198386           -0.127543   \n",
      "14956465           -0.490257           -0.417775           -0.344339   \n",
      "4501974            -0.444171           -0.288143           -0.211604   \n",
      "10795064           -0.461292           -0.355967           -0.272422   \n",
      "8151270             0.000000            0.000000            0.000000   \n",
      "...                      ...                 ...                 ...   \n",
      "1256776            -0.487700           -0.271383           -0.088734   \n",
      "8239048            -0.399476           -0.457467           -0.256637   \n",
      "16013432           -0.373818           -0.230347           -0.079722   \n",
      "3959756             0.012121           -0.223433           -0.025358   \n",
      "3858492            -0.480534           -0.530997           -0.317703   \n",
      "\n",
      "          covarep_feature_72  covarep_feature_73  \n",
      "5612632            -0.065221            0.111465  \n",
      "14956465           -0.414802           -0.291674  \n",
      "4501974            -0.161722           -0.100491  \n",
      "10795064           -0.272613           -0.095764  \n",
      "8151270             0.000000            0.000000  \n",
      "...                      ...                 ...  \n",
      "1256776             0.085087            0.108276  \n",
      "8239048            -0.144831           -0.110122  \n",
      "16013432            0.058426            0.161268  \n",
      "3959756             0.133247            0.225767  \n",
      "3858492            -0.255906           -0.294998  \n",
      "\n",
      "[1676434 rows x 74 columns]\n",
      "          Sentiment     Happy       Sad     Anger  Surprise   Disgust  \\\n",
      "5612632   -0.333333  0.000000  0.333333  0.666667  0.000000  1.000000   \n",
      "14956465   1.000000  0.000000  0.666667  0.000000  0.000000  0.000000   \n",
      "4501974    0.333333  0.000000  0.333333  0.000000  0.000000  0.000000   \n",
      "10795064  -1.000000  0.000000  0.333333  0.333333  0.000000  0.333333   \n",
      "8151270    0.333333  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "...             ...       ...       ...       ...       ...       ...   \n",
      "1256776   -2.000000  0.000000  0.666667  0.333333  0.666667  2.333333   \n",
      "8239048    1.000000  0.666667  0.333333  0.000000  0.333333  0.000000   \n",
      "16013432   1.666667  1.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3959756    1.333333  1.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "3858492    0.000000  2.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "              Fear  \n",
      "5612632   0.000000  \n",
      "14956465  0.666667  \n",
      "4501974   0.000000  \n",
      "10795064  0.666667  \n",
      "8151270   0.000000  \n",
      "...            ...  \n",
      "1256776   0.000000  \n",
      "8239048   0.000000  \n",
      "16013432  0.000000  \n",
      "3959756   0.000000  \n",
      "3858492   0.000000  \n",
      "\n",
      "[1676434 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_combined)\n",
    "print(y_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the sampled data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y_combined, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error, explained_variance_score\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.svm import SVR\n",
    "import xgboost as xgb\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.27\n",
      "R^2 Score: 0.06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train a regression model\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse:.2f}')\n",
    "print(f'R^2 Score: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m31433/31433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m349s\u001b[0m 11ms/step - Anger_loss: 0.1495 - Anger_mae: 0.2173 - Disgust_loss: 0.1284 - Disgust_mae: 0.1678 - Fear_loss: 0.0608 - Fear_mae: 0.0744 - Happy_loss: 0.4190 - Happy_mae: 0.4950 - Sad_loss: 0.1457 - Sad_mae: 0.2248 - Sentiment_loss: 1.2019 - Sentiment_mae: 0.8366 - Surprise_loss: 0.0531 - Surprise_mae: 0.0678 - loss: 2.1584 - val_Anger_loss: 0.1246 - val_Anger_mae: 0.2336 - val_Disgust_loss: 0.1005 - val_Disgust_mae: 0.1873 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.0994 - val_Happy_loss: 0.3753 - val_Happy_mae: 0.4790 - val_Sad_loss: 0.1083 - val_Sad_mae: 0.2427 - val_Sentiment_loss: 1.1427 - val_Sentiment_mae: 0.8164 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0913 - val_loss: 1.9133 - learning_rate: 5.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m31433/31433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 10ms/step - Anger_loss: 0.1252 - Anger_mae: 0.2358 - Disgust_loss: 0.1012 - Disgust_mae: 0.1862 - Fear_loss: 0.0319 - Fear_mae: 0.0995 - Happy_loss: 0.3771 - Happy_mae: 0.4836 - Sad_loss: 0.1083 - Sad_mae: 0.2377 - Sentiment_loss: 1.1488 - Sentiment_mae: 0.8176 - Surprise_loss: 0.0303 - Surprise_mae: 0.0913 - loss: 1.9228 - val_Anger_loss: 0.1240 - val_Anger_mae: 0.2396 - val_Disgust_loss: 0.0998 - val_Disgust_mae: 0.1879 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.1007 - val_Happy_loss: 0.3725 - val_Happy_mae: 0.4818 - val_Sad_loss: 0.1078 - val_Sad_mae: 0.2378 - val_Sentiment_loss: 1.1308 - val_Sentiment_mae: 0.8116 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0911 - val_loss: 1.8968 - learning_rate: 5.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m31433/31433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m275s\u001b[0m 9ms/step - Anger_loss: 0.1247 - Anger_mae: 0.2350 - Disgust_loss: 0.1007 - Disgust_mae: 0.1852 - Fear_loss: 0.0318 - Fear_mae: 0.0994 - Happy_loss: 0.3756 - Happy_mae: 0.4822 - Sad_loss: 0.1078 - Sad_mae: 0.2371 - Sentiment_loss: 1.1414 - Sentiment_mae: 0.8155 - Surprise_loss: 0.0302 - Surprise_mae: 0.0912 - loss: 1.9122 - val_Anger_loss: 0.1244 - val_Anger_mae: 0.2219 - val_Disgust_loss: 0.1003 - val_Disgust_mae: 0.1720 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.1018 - val_Happy_loss: 0.3719 - val_Happy_mae: 0.4811 - val_Sad_loss: 0.1077 - val_Sad_mae: 0.2370 - val_Sentiment_loss: 1.1323 - val_Sentiment_mae: 0.8114 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0913 - val_loss: 1.8986 - learning_rate: 5.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m31433/31433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 11ms/step - Anger_loss: 0.1245 - Anger_mae: 0.2344 - Disgust_loss: 0.1004 - Disgust_mae: 0.1847 - Fear_loss: 0.0319 - Fear_mae: 0.0995 - Happy_loss: 0.3752 - Happy_mae: 0.4816 - Sad_loss: 0.1080 - Sad_mae: 0.2373 - Sentiment_loss: 1.1378 - Sentiment_mae: 0.8147 - Surprise_loss: 0.0304 - Surprise_mae: 0.0915 - loss: 1.9081 - val_Anger_loss: 0.1237 - val_Anger_mae: 0.2324 - val_Disgust_loss: 0.0993 - val_Disgust_mae: 0.1841 - val_Fear_loss: 0.0318 - val_Fear_mae: 0.1005 - val_Happy_loss: 0.3720 - val_Happy_mae: 0.4832 - val_Sad_loss: 0.1077 - val_Sad_mae: 0.2340 - val_Sentiment_loss: 1.1234 - val_Sentiment_mae: 0.8086 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0921 - val_loss: 1.8880 - learning_rate: 5.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m31433/31433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m230s\u001b[0m 7ms/step - Anger_loss: 0.1243 - Anger_mae: 0.2343 - Disgust_loss: 0.1000 - Disgust_mae: 0.1842 - Fear_loss: 0.0319 - Fear_mae: 0.0994 - Happy_loss: 0.3744 - Happy_mae: 0.4808 - Sad_loss: 0.1077 - Sad_mae: 0.2368 - Sentiment_loss: 1.1340 - Sentiment_mae: 0.8136 - Surprise_loss: 0.0303 - Surprise_mae: 0.0912 - loss: 1.9025 - val_Anger_loss: 0.1231 - val_Anger_mae: 0.2319 - val_Disgust_loss: 0.0992 - val_Disgust_mae: 0.1784 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.0994 - val_Happy_loss: 0.3717 - val_Happy_mae: 0.4858 - val_Sad_loss: 0.1077 - val_Sad_mae: 0.2338 - val_Sentiment_loss: 1.1200 - val_Sentiment_mae: 0.8075 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0884 - val_loss: 1.8836 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m31433/31433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2ms/step - Anger_loss: 0.1241 - Anger_mae: 0.2340 - Disgust_loss: 0.0998 - Disgust_mae: 0.1839 - Fear_loss: 0.0319 - Fear_mae: 0.0995 - Happy_loss: 0.3737 - Happy_mae: 0.4802 - Sad_loss: 0.1077 - Sad_mae: 0.2367 - Sentiment_loss: 1.1321 - Sentiment_mae: 0.8132 - Surprise_loss: 0.0303 - Surprise_mae: 0.0913 - loss: 1.8997 - val_Anger_loss: 0.1232 - val_Anger_mae: 0.2308 - val_Disgust_loss: 0.0986 - val_Disgust_mae: 0.1817 - val_Fear_loss: 0.0318 - val_Fear_mae: 0.0997 - val_Happy_loss: 0.3702 - val_Happy_mae: 0.4728 - val_Sad_loss: 0.1076 - val_Sad_mae: 0.2393 - val_Sentiment_loss: 1.1150 - val_Sentiment_mae: 0.8069 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0885 - val_loss: 1.8765 - learning_rate: 5.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m31433/31433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2ms/step - Anger_loss: 0.1236 - Anger_mae: 0.2333 - Disgust_loss: 0.0997 - Disgust_mae: 0.1835 - Fear_loss: 0.0318 - Fear_mae: 0.0993 - Happy_loss: 0.3732 - Happy_mae: 0.4798 - Sad_loss: 0.1076 - Sad_mae: 0.2366 - Sentiment_loss: 1.1291 - Sentiment_mae: 0.8125 - Surprise_loss: 0.0302 - Surprise_mae: 0.0913 - loss: 1.8952 - val_Anger_loss: 0.1225 - val_Anger_mae: 0.2323 - val_Disgust_loss: 0.0984 - val_Disgust_mae: 0.1822 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.0975 - val_Happy_loss: 0.3716 - val_Happy_mae: 0.4791 - val_Sad_loss: 0.1073 - val_Sad_mae: 0.2358 - val_Sentiment_loss: 1.1102 - val_Sentiment_mae: 0.8057 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0903 - val_loss: 1.8720 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m31433/31433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 2ms/step - Anger_loss: 0.1235 - Anger_mae: 0.2332 - Disgust_loss: 0.0999 - Disgust_mae: 0.1837 - Fear_loss: 0.0317 - Fear_mae: 0.0990 - Happy_loss: 0.3733 - Happy_mae: 0.4798 - Sad_loss: 0.1075 - Sad_mae: 0.2365 - Sentiment_loss: 1.1278 - Sentiment_mae: 0.8123 - Surprise_loss: 0.0304 - Surprise_mae: 0.0915 - loss: 1.8942 - val_Anger_loss: 0.1226 - val_Anger_mae: 0.2330 - val_Disgust_loss: 0.0987 - val_Disgust_mae: 0.1848 - val_Fear_loss: 0.0320 - val_Fear_mae: 0.0981 - val_Happy_loss: 0.3718 - val_Happy_mae: 0.4786 - val_Sad_loss: 0.1076 - val_Sad_mae: 0.2351 - val_Sentiment_loss: 1.1092 - val_Sentiment_mae: 0.8052 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0911 - val_loss: 1.8720 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m31433/31433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m76s\u001b[0m 2ms/step - Anger_loss: 0.1234 - Anger_mae: 0.2328 - Disgust_loss: 0.0994 - Disgust_mae: 0.1831 - Fear_loss: 0.0319 - Fear_mae: 0.0994 - Happy_loss: 0.3728 - Happy_mae: 0.4793 - Sad_loss: 0.1076 - Sad_mae: 0.2365 - Sentiment_loss: 1.1257 - Sentiment_mae: 0.8114 - Surprise_loss: 0.0302 - Surprise_mae: 0.0911 - loss: 1.8909 - val_Anger_loss: 0.1230 - val_Anger_mae: 0.2283 - val_Disgust_loss: 0.0991 - val_Disgust_mae: 0.1757 - val_Fear_loss: 0.0318 - val_Fear_mae: 0.0992 - val_Happy_loss: 0.3698 - val_Happy_mae: 0.4778 - val_Sad_loss: 0.1075 - val_Sad_mae: 0.2367 - val_Sentiment_loss: 1.1125 - val_Sentiment_mae: 0.8042 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0905 - val_loss: 1.8738 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m31433/31433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m102s\u001b[0m 3ms/step - Anger_loss: 0.1234 - Anger_mae: 0.2328 - Disgust_loss: 0.0994 - Disgust_mae: 0.1831 - Fear_loss: 0.0319 - Fear_mae: 0.0994 - Happy_loss: 0.3726 - Happy_mae: 0.4792 - Sad_loss: 0.1077 - Sad_mae: 0.2365 - Sentiment_loss: 1.1245 - Sentiment_mae: 0.8112 - Surprise_loss: 0.0303 - Surprise_mae: 0.0913 - loss: 1.8899 - val_Anger_loss: 0.1223 - val_Anger_mae: 0.2306 - val_Disgust_loss: 0.0982 - val_Disgust_mae: 0.1782 - val_Fear_loss: 0.0318 - val_Fear_mae: 0.0991 - val_Happy_loss: 0.3721 - val_Happy_mae: 0.4774 - val_Sad_loss: 0.1074 - val_Sad_mae: 0.2337 - val_Sentiment_loss: 1.1055 - val_Sentiment_mae: 0.8029 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0871 - val_loss: 1.8674 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m31433/31433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 2ms/step - Anger_loss: 0.1235 - Anger_mae: 0.2329 - Disgust_loss: 0.0994 - Disgust_mae: 0.1829 - Fear_loss: 0.0318 - Fear_mae: 0.0994 - Happy_loss: 0.3726 - Happy_mae: 0.4791 - Sad_loss: 0.1075 - Sad_mae: 0.2365 - Sentiment_loss: 1.1226 - Sentiment_mae: 0.8104 - Surprise_loss: 0.0303 - Surprise_mae: 0.0911 - loss: 1.8878 - val_Anger_loss: 0.1226 - val_Anger_mae: 0.2295 - val_Disgust_loss: 0.0985 - val_Disgust_mae: 0.1777 - val_Fear_loss: 0.0318 - val_Fear_mae: 0.1008 - val_Happy_loss: 0.3704 - val_Happy_mae: 0.4743 - val_Sad_loss: 0.1071 - val_Sad_mae: 0.2365 - val_Sentiment_loss: 1.1054 - val_Sentiment_mae: 0.8027 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0896 - val_loss: 1.8660 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m31433/31433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 2ms/step - Anger_loss: 0.1232 - Anger_mae: 0.2326 - Disgust_loss: 0.0995 - Disgust_mae: 0.1830 - Fear_loss: 0.0318 - Fear_mae: 0.0994 - Happy_loss: 0.3723 - Happy_mae: 0.4789 - Sad_loss: 0.1075 - Sad_mae: 0.2363 - Sentiment_loss: 1.1224 - Sentiment_mae: 0.8108 - Surprise_loss: 0.0303 - Surprise_mae: 0.0913 - loss: 1.8870 - val_Anger_loss: 0.1226 - val_Anger_mae: 0.2274 - val_Disgust_loss: 0.0985 - val_Disgust_mae: 0.1774 - val_Fear_loss: 0.0318 - val_Fear_mae: 0.0996 - val_Happy_loss: 0.3694 - val_Happy_mae: 0.4784 - val_Sad_loss: 0.1073 - val_Sad_mae: 0.2351 - val_Sentiment_loss: 1.1070 - val_Sentiment_mae: 0.8032 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0916 - val_loss: 1.8667 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m31433/31433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2ms/step - Anger_loss: 0.1232 - Anger_mae: 0.2325 - Disgust_loss: 0.0995 - Disgust_mae: 0.1830 - Fear_loss: 0.0319 - Fear_mae: 0.0995 - Happy_loss: 0.3719 - Happy_mae: 0.4784 - Sad_loss: 0.1075 - Sad_mae: 0.2363 - Sentiment_loss: 1.1209 - Sentiment_mae: 0.8101 - Surprise_loss: 0.0303 - Surprise_mae: 0.0914 - loss: 1.8853 - val_Anger_loss: 0.1222 - val_Anger_mae: 0.2337 - val_Disgust_loss: 0.0985 - val_Disgust_mae: 0.1852 - val_Fear_loss: 0.0318 - val_Fear_mae: 0.1001 - val_Happy_loss: 0.3686 - val_Happy_mae: 0.4770 - val_Sad_loss: 0.1074 - val_Sad_mae: 0.2353 - val_Sentiment_loss: 1.1026 - val_Sentiment_mae: 0.8026 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0906 - val_loss: 1.8612 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m31433/31433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m67s\u001b[0m 2ms/step - Anger_loss: 0.1234 - Anger_mae: 0.2326 - Disgust_loss: 0.0993 - Disgust_mae: 0.1828 - Fear_loss: 0.0318 - Fear_mae: 0.0993 - Happy_loss: 0.3714 - Happy_mae: 0.4781 - Sad_loss: 0.1074 - Sad_mae: 0.2362 - Sentiment_loss: 1.1197 - Sentiment_mae: 0.8096 - Surprise_loss: 0.0302 - Surprise_mae: 0.0912 - loss: 1.8832 - val_Anger_loss: 0.1220 - val_Anger_mae: 0.2354 - val_Disgust_loss: 0.0981 - val_Disgust_mae: 0.1844 - val_Fear_loss: 0.0318 - val_Fear_mae: 0.0980 - val_Happy_loss: 0.3683 - val_Happy_mae: 0.4736 - val_Sad_loss: 0.1075 - val_Sad_mae: 0.2381 - val_Sentiment_loss: 1.1011 - val_Sentiment_mae: 0.8022 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0886 - val_loss: 1.8589 - learning_rate: 5.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m31433/31433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2ms/step - Anger_loss: 0.1232 - Anger_mae: 0.2324 - Disgust_loss: 0.0990 - Disgust_mae: 0.1826 - Fear_loss: 0.0318 - Fear_mae: 0.0994 - Happy_loss: 0.3714 - Happy_mae: 0.4780 - Sad_loss: 0.1074 - Sad_mae: 0.2362 - Sentiment_loss: 1.1194 - Sentiment_mae: 0.8096 - Surprise_loss: 0.0302 - Surprise_mae: 0.0912 - loss: 1.8824 - val_Anger_loss: 0.1222 - val_Anger_mae: 0.2313 - val_Disgust_loss: 0.0981 - val_Disgust_mae: 0.1818 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.0955 - val_Happy_loss: 0.3718 - val_Happy_mae: 0.4705 - val_Sad_loss: 0.1070 - val_Sad_mae: 0.2372 - val_Sentiment_loss: 1.1014 - val_Sentiment_mae: 0.8022 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0909 - val_loss: 1.8624 - learning_rate: 5.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m31433/31433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 10ms/step - Anger_loss: 0.1230 - Anger_mae: 0.2323 - Disgust_loss: 0.0990 - Disgust_mae: 0.1824 - Fear_loss: 0.0318 - Fear_mae: 0.0994 - Happy_loss: 0.3712 - Happy_mae: 0.4778 - Sad_loss: 0.1074 - Sad_mae: 0.2361 - Sentiment_loss: 1.1181 - Sentiment_mae: 0.8094 - Surprise_loss: 0.0303 - Surprise_mae: 0.0912 - loss: 1.8809 - val_Anger_loss: 0.1219 - val_Anger_mae: 0.2332 - val_Disgust_loss: 0.0985 - val_Disgust_mae: 0.1791 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.0990 - val_Happy_loss: 0.3710 - val_Happy_mae: 0.4794 - val_Sad_loss: 0.1077 - val_Sad_mae: 0.2313 - val_Sentiment_loss: 1.1020 - val_Sentiment_mae: 0.8014 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0907 - val_loss: 1.8630 - learning_rate: 5.0000e-04\n",
      "Epoch 17/50\n",
      "\u001b[1m31433/31433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2ms/step - Anger_loss: 0.1227 - Anger_mae: 0.2319 - Disgust_loss: 0.0991 - Disgust_mae: 0.1823 - Fear_loss: 0.0318 - Fear_mae: 0.0993 - Happy_loss: 0.3713 - Happy_mae: 0.4778 - Sad_loss: 0.1074 - Sad_mae: 0.2360 - Sentiment_loss: 1.1179 - Sentiment_mae: 0.8093 - Surprise_loss: 0.0302 - Surprise_mae: 0.0912 - loss: 1.8804 - val_Anger_loss: 0.1226 - val_Anger_mae: 0.2279 - val_Disgust_loss: 0.0989 - val_Disgust_mae: 0.1762 - val_Fear_loss: 0.0318 - val_Fear_mae: 0.0996 - val_Happy_loss: 0.3759 - val_Happy_mae: 0.4785 - val_Sad_loss: 0.1077 - val_Sad_mae: 0.2360 - val_Sentiment_loss: 1.1048 - val_Sentiment_mae: 0.8022 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0898 - val_loss: 1.8718 - learning_rate: 5.0000e-04\n",
      "Epoch 18/50\n",
      "\u001b[1m31433/31433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2ms/step - Anger_loss: 0.1227 - Anger_mae: 0.2318 - Disgust_loss: 0.0991 - Disgust_mae: 0.1823 - Fear_loss: 0.0319 - Fear_mae: 0.0994 - Happy_loss: 0.3709 - Happy_mae: 0.4776 - Sad_loss: 0.1073 - Sad_mae: 0.2359 - Sentiment_loss: 1.1166 - Sentiment_mae: 0.8091 - Surprise_loss: 0.0303 - Surprise_mae: 0.0913 - loss: 1.8787 - val_Anger_loss: 0.1218 - val_Anger_mae: 0.2322 - val_Disgust_loss: 0.0981 - val_Disgust_mae: 0.1816 - val_Fear_loss: 0.0318 - val_Fear_mae: 0.0993 - val_Happy_loss: 0.3798 - val_Happy_mae: 0.4707 - val_Sad_loss: 0.1077 - val_Sad_mae: 0.2381 - val_Sentiment_loss: 1.0970 - val_Sentiment_mae: 0.8007 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0886 - val_loss: 1.8662 - learning_rate: 2.5000e-04\n",
      "Epoch 19/50\n",
      "\u001b[1m31433/31433\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 2ms/step - Anger_loss: 0.1226 - Anger_mae: 0.2316 - Disgust_loss: 0.0990 - Disgust_mae: 0.1821 - Fear_loss: 0.0319 - Fear_mae: 0.0996 - Happy_loss: 0.3706 - Happy_mae: 0.4771 - Sad_loss: 0.1071 - Sad_mae: 0.2358 - Sentiment_loss: 1.1157 - Sentiment_mae: 0.8087 - Surprise_loss: 0.0304 - Surprise_mae: 0.0914 - loss: 1.8773 - val_Anger_loss: 0.1217 - val_Anger_mae: 0.2321 - val_Disgust_loss: 0.0983 - val_Disgust_mae: 0.1833 - val_Fear_loss: 0.0318 - val_Fear_mae: 0.1015 - val_Happy_loss: 0.3852 - val_Happy_mae: 0.4753 - val_Sad_loss: 0.1072 - val_Sad_mae: 0.2359 - val_Sentiment_loss: 1.0949 - val_Sentiment_mae: 0.7998 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0915 - val_loss: 1.8691 - learning_rate: 2.5000e-04\n",
      "\u001b[1m62866/62866\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 570us/step\n",
      "Multi-task NN Output (Sentiment):\n",
      "  Accuracy: 0.55\n",
      "  F1 Score: 0.36\n",
      "  Precision: 0.35\n",
      "  Recall: 0.40\n",
      "  Mean Absolute Error: 0.80\n",
      "  Mean Squared Error: 1.10\n",
      "  Root Mean Squared Error: 1.05\n",
      "  R^2 Score: 0.09\n",
      "  Explained Variance Score: 0.09\n",
      "\n",
      "Multi-task NN Output (Happy):\n",
      "  Accuracy: 0.58\n",
      "  F1 Score: 0.58\n",
      "  Precision: 0.66\n",
      "  Recall: 0.52\n",
      "  Mean Absolute Error: 0.47\n",
      "  Mean Squared Error: 0.37\n",
      "  Root Mean Squared Error: 0.61\n",
      "  R^2 Score: 0.08\n",
      "  Explained Variance Score: 0.08\n",
      "\n",
      "Multi-task NN Output (Sad):\n",
      "  Accuracy: 0.73\n",
      "  F1 Score: 0.00\n",
      "  Precision: 0.68\n",
      "  Recall: 0.00\n",
      "  Mean Absolute Error: 0.24\n",
      "  Mean Squared Error: 0.11\n",
      "  Root Mean Squared Error: 0.33\n",
      "  R^2 Score: 0.03\n",
      "  Explained Variance Score: 0.03\n",
      "\n",
      "Multi-task NN Output (Anger):\n",
      "  Accuracy: 0.79\n",
      "  F1 Score: 0.01\n",
      "  Precision: 0.70\n",
      "  Recall: 0.01\n",
      "  Mean Absolute Error: 0.24\n",
      "  Mean Squared Error: 0.12\n",
      "  Root Mean Squared Error: 0.35\n",
      "  R^2 Score: 0.04\n",
      "  Explained Variance Score: 0.04\n",
      "\n",
      "Multi-task NN Output (Surprise):\n",
      "  Accuracy: 0.89\n",
      "  F1 Score: 0.00\n",
      "  Precision: 0.00\n",
      "  Recall: 0.00\n",
      "  Mean Absolute Error: 0.09\n",
      "  Mean Squared Error: 0.03\n",
      "  Root Mean Squared Error: 0.17\n",
      "  R^2 Score: 0.01\n",
      "  Explained Variance Score: 0.01\n",
      "\n",
      "Multi-task NN Output (Disgust):\n",
      "  Accuracy: 0.83\n",
      "  F1 Score: 0.03\n",
      "  Precision: 0.71\n",
      "  Recall: 0.01\n",
      "  Mean Absolute Error: 0.18\n",
      "  Mean Squared Error: 0.10\n",
      "  Root Mean Squared Error: 0.31\n",
      "  R^2 Score: 0.06\n",
      "  Explained Variance Score: 0.06\n",
      "\n",
      "Multi-task NN Output (Fear):\n",
      "  Accuracy: 0.89\n",
      "  F1 Score: 0.00\n",
      "  Precision: 0.00\n",
      "  Recall: 0.00\n",
      "  Mean Absolute Error: 0.10\n",
      "  Mean Squared Error: 0.03\n",
      "  Root Mean Squared Error: 0.18\n",
      "  R^2 Score: 0.00\n",
      "  Explained Variance Score: 0.00\n",
      "\n",
      "Overall Accuracy (emotions): 0.78\n",
      "Overall F1 Score (emotions): 0.10\n",
      "Overall Precision (emotions): 0.46\n",
      "Overall Recall (emotions): 0.09\n",
      "Sentiment Accuracy: 0.55\n",
      "Sentiment F1 Score: 0.36\n",
      "Sentiment Precision: 0.35\n",
      "Sentiment Recall: 0.40\n"
     ]
    }
   ],
   "source": [
    "import numpy as np  \n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Define input layer and shared layers with optimization techniques\n",
    "input_layer = layers.Input(shape=(X_train.shape[1],))\n",
    "shared = layers.Dense(128, activation='relu')(input_layer)\n",
    "shared = layers.BatchNormalization()(shared)\n",
    "shared = layers.Dropout(0.4)(shared)\n",
    "shared = layers.Dense(64, activation='relu')(shared)\n",
    "shared = layers.BatchNormalization()(shared)\n",
    "shared = layers.Dropout(0.3)(shared)\n",
    "\n",
    "# Sentiment output (range [-3,3]) with tanh activation\n",
    "sentiment_output = layers.Dense(1, activation='tanh', name='Sentiment')(shared)\n",
    "\n",
    "# Emotion outputs (range [0,3]) with ReLU activation\n",
    "emotion_outputs = {}\n",
    "for emotion_name in [\"Happy\", \"Sad\", \"Anger\", \"Surprise\", \"Disgust\", \"Fear\"]:\n",
    "    emotion_outputs[emotion_name] = layers.Dense(1, activation='relu', name=emotion_name)(shared)\n",
    "\n",
    "# Create the model\n",
    "model_nn = models.Model(inputs=input_layer, outputs=[sentiment_output] + list(emotion_outputs.values()))\n",
    "\n",
    "# Compile the model with a lower learning rate and specify metrics for each output\n",
    "optimizer = Adam(learning_rate=0.0005)\n",
    "model_nn.compile(\n",
    "    optimizer=optimizer,\n",
    "    loss={'Sentiment': 'mse', **{name: 'mse' for name in emotion_outputs.keys()}},\n",
    "    metrics={'Sentiment': ['mae'], **{name: ['mae'] for name in emotion_outputs.keys()}}\n",
    ")\n",
    "\n",
    "# Prepare training and validation targets\n",
    "train_targets = [y_train['Sentiment']] + [y_train[emotion] for emotion in emotion_outputs.keys()]\n",
    "val_targets = [y_test['Sentiment']] + [y_test[emotion] for emotion in emotion_outputs.keys()]\n",
    "\n",
    "# Define callbacks for early stopping and learning rate scheduling\n",
    "callbacks_list = [\n",
    "    callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "]\n",
    "\n",
    "# Train the model\n",
    "model_nn.fit(\n",
    "    X_train, train_targets,\n",
    "    validation_data=(X_test, val_targets),\n",
    "    epochs=50, batch_size=256,\n",
    "    callbacks=callbacks_list\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_nn = model_nn.predict(X_test)\n",
    "\n",
    "# Initialize lists to accumulate accuracy, F1, precision, and recall scores for each emotion\n",
    "accuracy_list = []\n",
    "f1_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "\n",
    "# Evaluation: Calculate MAE, MSE, RMSE, R^2, EVS, Accuracy, F1, Precision, and Recall\n",
    "output_names = ['Sentiment'] + list(emotion_outputs.keys())\n",
    "for i, output_name in enumerate(output_names):\n",
    "    # True and predicted values for the current output\n",
    "    y_true = y_test[output_name].values.flatten()\n",
    "    y_pred = y_pred_nn[i].flatten()\n",
    "\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    evs = explained_variance_score(y_true, y_pred)\n",
    "\n",
    "    # Sentiment classification: -1 for negative, 0 for neutral, 1 for positive\n",
    "    if output_name == \"Sentiment\":\n",
    "        y_true_class = np.where(y_true > 0, 1, np.where(y_true < 0, -1, 0))\n",
    "        y_pred_class = np.where(y_pred > 0, 1, np.where(y_pred < 0, -1, 0))\n",
    "\n",
    "        sentiment_accuracy = accuracy_score(y_true_class, y_pred_class)\n",
    "        sentiment_f1 = f1_score(y_true_class, y_pred_class, average=\"macro\")\n",
    "        sentiment_precision = precision_score(y_true_class, y_pred_class, average=\"macro\", zero_division=0)\n",
    "        sentiment_recall = recall_score(y_true_class, y_pred_class, average=\"macro\", zero_division=0)\n",
    "\n",
    "        print(f'Multi-task NN Output (Sentiment):')\n",
    "        print(f'  Accuracy: {sentiment_accuracy:.2f}')\n",
    "        print(f'  F1 Score: {sentiment_f1:.2f}')\n",
    "        print(f'  Precision: {sentiment_precision:.2f}')\n",
    "        print(f'  Recall: {sentiment_recall:.2f}')\n",
    "    \n",
    "    # For emotions, calculate accuracy, F1, precision, and recall using a presence threshold\n",
    "    else:\n",
    "        threshold = 0.5  # Threshold for presence\n",
    "        y_true_binary = (y_true > 0).astype(int)  # Presence if > 0\n",
    "        y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(y_true_binary, y_pred_binary)\n",
    "        f1 = f1_score(y_true_binary, y_pred_binary)\n",
    "        precision = precision_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "        recall = recall_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "\n",
    "        # Append accuracy, F1, precision, and recall to lists\n",
    "        accuracy_list.append(accuracy)\n",
    "        f1_list.append(f1)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "\n",
    "        print(f'Multi-task NN Output ({output_name}):')\n",
    "        print(f'  Accuracy: {accuracy:.2f}')\n",
    "        print(f'  F1 Score: {f1:.2f}')\n",
    "        print(f'  Precision: {precision:.2f}')\n",
    "        print(f'  Recall: {recall:.2f}')\n",
    "\n",
    "    print(f'  Mean Absolute Error: {mae:.2f}')\n",
    "    print(f'  Mean Squared Error: {mse:.2f}')\n",
    "    print(f'  Root Mean Squared Error: {rmse:.2f}')\n",
    "    print(f'  R^2 Score: {r2:.2f}')\n",
    "    print(f'  Explained Variance Score: {evs:.2f}')\n",
    "    print()\n",
    "\n",
    "# Calculate and print the overall metrics for emotions and sentiment\n",
    "overall_accuracy = np.mean(accuracy_list)\n",
    "overall_f1_score = np.mean(f1_list)\n",
    "overall_precision = np.mean(precision_list)\n",
    "overall_recall = np.mean(recall_list)\n",
    "\n",
    "print(f'Overall Accuracy (emotions): {overall_accuracy:.2f}')\n",
    "print(f'Overall F1 Score (emotions): {overall_f1_score:.2f}')\n",
    "print(f'Overall Precision (emotions): {overall_precision:.2f}')\n",
    "print(f'Overall Recall (emotions): {overall_recall:.2f}')\n",
    "print(f'Sentiment Accuracy: {sentiment_accuracy:.2f}')\n",
    "print(f'Sentiment F1 Score: {sentiment_f1:.2f}')\n",
    "print(f'Sentiment Precision: {sentiment_precision:.2f}')\n",
    "print(f'Sentiment Recall: {sentiment_recall:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\deeps\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n",
      "c:\\Users\\deeps\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [14:00:24] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0ed59c031377d09b8-1\\xgboost\\xgboost-ci-windows\\src\\common\\error_msg.cc:27: The tree method `gpu_hist` is deprecated since 2.0.0. To use GPU training, set the `device` parameter to CUDA instead.\n",
      "\n",
      "    E.g. tree_method = \"hist\", device = \"cuda\"\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters for each output model:\n",
      "{'subsample': 0.8, 'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.2, 'colsample_bytree': 1.0}\n",
      "{'subsample': 0.6, 'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.2, 'colsample_bytree': 0.7}\n",
      "{'subsample': 0.6, 'n_estimators': 200, 'max_depth': 10, 'learning_rate': 0.1, 'colsample_bytree': 0.5}\n",
      "{'subsample': 0.6, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.2, 'colsample_bytree': 1.0}\n",
      "{'subsample': 1.0, 'n_estimators': 500, 'max_depth': 10, 'learning_rate': 0.2, 'colsample_bytree': 1.0}\n",
      "{'subsample': 1.0, 'n_estimators': 100, 'max_depth': 10, 'learning_rate': 0.2, 'colsample_bytree': 1.0}\n",
      "{'subsample': 0.8, 'n_estimators': 500, 'max_depth': 8, 'learning_rate': 0.2, 'colsample_bytree': 0.7}\n",
      "XGBoost Output (Sentiment):\n",
      "  Mean Absolute Error: 0.72\n",
      "  Mean Squared Error: 0.88\n",
      "  Root Mean Squared Error: 0.94\n",
      "  R^2 Score: 0.27\n",
      "  Explained Variance Score: 0.27\n",
      "  Sentiment Accuracy: 0.60\n",
      "  Sentiment F1 Score: 0.42\n",
      "  Sentiment Precision: 0.39\n",
      "  Sentiment Recall: 0.47\n",
      "\n",
      "XGBoost Output (Happy):\n",
      "  Mean Absolute Error: 0.42\n",
      "  Mean Squared Error: 0.30\n",
      "  Root Mean Squared Error: 0.55\n",
      "  R^2 Score: 0.26\n",
      "  Explained Variance Score: 0.26\n",
      "  Accuracy: 0.65\n",
      "  F1 Score: 0.66\n",
      "  Precision: 0.72\n",
      "  Recall: 0.60\n",
      "\n",
      "XGBoost Output (Sad):\n",
      "  Mean Absolute Error: 0.22\n",
      "  Mean Squared Error: 0.10\n",
      "  Root Mean Squared Error: 0.31\n",
      "  R^2 Score: 0.13\n",
      "  Explained Variance Score: 0.13\n",
      "  Accuracy: 0.73\n",
      "  F1 Score: 0.06\n",
      "  Precision: 0.90\n",
      "  Recall: 0.03\n",
      "\n",
      "XGBoost Output (Anger):\n",
      "  Mean Absolute Error: 0.21\n",
      "  Mean Squared Error: 0.11\n",
      "  Root Mean Squared Error: 0.33\n",
      "  R^2 Score: 0.15\n",
      "  Explained Variance Score: 0.15\n",
      "  Accuracy: 0.79\n",
      "  F1 Score: 0.11\n",
      "  Precision: 0.81\n",
      "  Recall: 0.06\n",
      "\n",
      "XGBoost Output (Surprise):\n",
      "  Mean Absolute Error: 0.08\n",
      "  Mean Squared Error: 0.02\n",
      "  Root Mean Squared Error: 0.16\n",
      "  R^2 Score: 0.19\n",
      "  Explained Variance Score: 0.19\n",
      "  Accuracy: 0.89\n",
      "  F1 Score: 0.03\n",
      "  Precision: 0.94\n",
      "  Recall: 0.02\n",
      "\n",
      "XGBoost Output (Disgust):\n",
      "  Mean Absolute Error: 0.17\n",
      "  Mean Squared Error: 0.09\n",
      "  Root Mean Squared Error: 0.30\n",
      "  R^2 Score: 0.17\n",
      "  Explained Variance Score: 0.17\n",
      "  Accuracy: 0.84\n",
      "  F1 Score: 0.11\n",
      "  Precision: 0.82\n",
      "  Recall: 0.06\n",
      "\n",
      "XGBoost Output (Fear):\n",
      "  Mean Absolute Error: 0.09\n",
      "  Mean Squared Error: 0.03\n",
      "  Root Mean Squared Error: 0.17\n",
      "  R^2 Score: 0.11\n",
      "  Explained Variance Score: 0.11\n",
      "  Accuracy: 0.89\n",
      "  F1 Score: 0.02\n",
      "  Precision: 0.96\n",
      "  Recall: 0.01\n",
      "\n",
      "Overall Model Evaluation:\n",
      "  Mean Absolute Error: 0.27\n",
      "  Mean Squared Error: 0.22\n",
      "  Root Mean Squared Error: 0.39\n",
      "  Average R^2 Score: 0.18\n",
      "  Average Explained Variance Score: 0.18\n",
      "  Overall Accuracy (emotions): 0.80\n",
      "  Overall F1 Score (emotions): 0.16\n",
      "  Overall Precision (emotions): 0.86\n",
      "  Overall Recall (emotions): 0.13\n",
      "  Sentiment Accuracy: 0.60\n",
      "  Sentiment F1 Score: 0.42\n",
      "  Sentiment Precision: 0.39\n",
      "  Sentiment Recall: 0.47\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score, accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are already defined\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the base XGBoost regressor with GPU acceleration\n",
    "base_model = xgb.XGBRegressor(objective='reg:squarederror', tree_method='gpu_hist', verbosity=0)\n",
    "\n",
    "# Hyperparameter grid for randomized search\n",
    "param_dist = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [4, 6, 8, 10],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.7, 1.0]\n",
    "}\n",
    "\n",
    "# Perform randomized search with cross-validation\n",
    "random_search = RandomizedSearchCV(\n",
    "    base_model, param_distributions=param_dist, n_iter=10,\n",
    "    scoring='neg_mean_squared_error', cv=3, verbose=1, n_jobs=2\n",
    ")\n",
    "multi_output_model = MultiOutputRegressor(random_search)\n",
    "multi_output_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get best hyperparameters from RandomizedSearchCV\n",
    "print(\"Best Hyperparameters for each output model:\")\n",
    "for estimator in multi_output_model.estimators_:\n",
    "    print(estimator.best_params_)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_xgb = multi_output_model.predict(X_test_scaled)\n",
    "\n",
    "# Define output names\n",
    "output_names = ['Sentiment', 'Happy', 'Sad', 'Anger', 'Surprise', 'Disgust', 'Fear']\n",
    "\n",
    "# Initialize accumulators for overall metrics\n",
    "overall_mae, overall_mse, overall_rmse, overall_r2, overall_evs = 0, 0, 0, 0, 0\n",
    "accuracy_list, f1_list, precision_list, recall_list = [], [], [], []\n",
    "\n",
    "# Evaluate each output\n",
    "for i, output_name in enumerate(output_names):\n",
    "    y_true = y_test.iloc[:, i]\n",
    "    y_pred = y_pred_xgb[:, i]\n",
    "\n",
    "    # Regression metrics\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    evs = explained_variance_score(y_true, y_pred)\n",
    "\n",
    "    print(f'XGBoost Output ({output_name}):')\n",
    "    print(f'  Mean Absolute Error: {mae:.2f}')\n",
    "    print(f'  Mean Squared Error: {mse:.2f}')\n",
    "    print(f'  Root Mean Squared Error: {rmse:.2f}')\n",
    "    print(f'  R^2 Score: {r2:.2f}')\n",
    "    print(f'  Explained Variance Score: {evs:.2f}')\n",
    "\n",
    "    # Sentiment classification: -1 for negative, 0 for neutral, 1 for positive\n",
    "    if output_name == \"Sentiment\":\n",
    "        y_true_class = np.where(y_true > 0, 1, np.where(y_true < 0, -1, 0))\n",
    "        y_pred_class = np.where(y_pred > 0, 1, np.where(y_pred < 0, -1, 0))\n",
    "\n",
    "        sentiment_accuracy = accuracy_score(y_true_class, y_pred_class)\n",
    "        sentiment_f1 = f1_score(y_true_class, y_pred_class, average=\"macro\")\n",
    "        sentiment_precision = precision_score(y_true_class, y_pred_class, average=\"macro\", zero_division=0)\n",
    "        sentiment_recall = recall_score(y_true_class, y_pred_class, average=\"macro\", zero_division=0)\n",
    "\n",
    "        print(f'  Sentiment Accuracy: {sentiment_accuracy:.2f}')\n",
    "        print(f'  Sentiment F1 Score: {sentiment_f1:.2f}')\n",
    "        print(f'  Sentiment Precision: {sentiment_precision:.2f}')\n",
    "        print(f'  Sentiment Recall: {sentiment_recall:.2f}')\n",
    "\n",
    "    # For emotion outputs, calculate accuracy, F1, precision, and recall\n",
    "    else:\n",
    "        threshold = 0.5\n",
    "        y_true_binary = (y_true > 0).astype(int)\n",
    "        y_pred_binary = (y_pred >= threshold).astype(int)\n",
    "\n",
    "        accuracy = accuracy_score(y_true_binary, y_pred_binary)\n",
    "        f1 = f1_score(y_true_binary, y_pred_binary)\n",
    "        precision = precision_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "        recall = recall_score(y_true_binary, y_pred_binary, zero_division=0)\n",
    "\n",
    "        # Append to accuracy, F1, precision, and recall lists\n",
    "        accuracy_list.append(accuracy)\n",
    "        f1_list.append(f1)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "\n",
    "        print(f'  Accuracy: {accuracy:.2f}')\n",
    "        print(f'  F1 Score: {f1:.2f}')\n",
    "        print(f'  Precision: {precision:.2f}')\n",
    "        print(f'  Recall: {recall:.2f}')\n",
    "\n",
    "    # Accumulate regression metrics for overall evaluation\n",
    "    overall_mae += mae\n",
    "    overall_mse += mse\n",
    "    overall_rmse += rmse\n",
    "    overall_r2 += r2\n",
    "    overall_evs += evs\n",
    "    print()\n",
    "\n",
    "# Calculate average metrics\n",
    "num_outputs = len(output_names)\n",
    "overall_mae /= num_outputs\n",
    "overall_mse /= num_outputs\n",
    "overall_rmse /= num_outputs\n",
    "overall_r2 /= num_outputs\n",
    "overall_evs /= num_outputs\n",
    "\n",
    "# Calculate overall accuracy, F1, precision, and recall for emotion outputs\n",
    "overall_accuracy = np.mean(accuracy_list)\n",
    "overall_f1_score = np.mean(f1_list)\n",
    "overall_precision = np.mean(precision_list)\n",
    "overall_recall = np.mean(recall_list)\n",
    "\n",
    "# Print overall evaluations\n",
    "print('Overall Model Evaluation:')\n",
    "print(f'  Mean Absolute Error: {overall_mae:.2f}')\n",
    "print(f'  Mean Squared Error: {overall_mse:.2f}')\n",
    "print(f'  Root Mean Squared Error: {overall_rmse:.2f}')\n",
    "print(f'  Average R^2 Score: {overall_r2:.2f}')\n",
    "print(f'  Average Explained Variance Score: {overall_evs:.2f}')\n",
    "print(f'  Overall Accuracy (emotions): {overall_accuracy:.2f}')\n",
    "print(f'  Overall F1 Score (emotions): {overall_f1_score:.2f}')\n",
    "print(f'  Overall Precision (emotions): {overall_precision:.2f}')\n",
    "print(f'  Overall Recall (emotions): {overall_recall:.2f}')\n",
    "print(f'  Sentiment Accuracy: {sentiment_accuracy:.2f}')\n",
    "print(f'  Sentiment F1 Score: {sentiment_f1:.2f}')\n",
    "print(f'  Sentiment Precision: {sentiment_precision:.2f}')\n",
    "print(f'  Sentiment Recall: {sentiment_recall:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVR Output Sentiment:\n",
      "  Mean Absolute Error: 0.88\n",
      "  Mean Squared Error: 1.31\n",
      "  Root Mean Squared Error: 1.15\n",
      "  R^2 Score: -0.01\n",
      "  Explained Variance Score: -0.01\n",
      "\n",
      "SVR Output Happy:\n",
      "  Mean Absolute Error: 0.49\n",
      "  Mean Squared Error: 0.49\n",
      "  Root Mean Squared Error: 0.70\n",
      "  R^2 Score: -0.12\n",
      "  Explained Variance Score: -0.02\n",
      "\n",
      "SVR Output Sad:\n",
      "  Mean Absolute Error: 0.19\n",
      "  Mean Squared Error: 0.09\n",
      "  Root Mean Squared Error: 0.29\n",
      "  R^2 Score: -0.06\n",
      "  Explained Variance Score: -0.00\n",
      "\n",
      "SVR Output Anger:\n",
      "  Mean Absolute Error: 0.20\n",
      "  Mean Squared Error: 0.15\n",
      "  Root Mean Squared Error: 0.38\n",
      "  R^2 Score: -0.04\n",
      "  Explained Variance Score: 0.00\n",
      "\n",
      "SVR Output Surprise:\n",
      "  Mean Absolute Error: 0.13\n",
      "  Mean Squared Error: 0.05\n",
      "  Root Mean Squared Error: 0.22\n",
      "  R^2 Score: -0.01\n",
      "  Explained Variance Score: -0.01\n",
      "\n",
      "SVR Output Disgust:\n",
      "  Mean Absolute Error: 0.18\n",
      "  Mean Squared Error: 0.13\n",
      "  Root Mean Squared Error: 0.36\n",
      "  R^2 Score: -0.02\n",
      "  Explained Variance Score: -0.00\n",
      "\n",
      "SVR Output Fear:\n",
      "  Mean Absolute Error: 0.12\n",
      "  Mean Squared Error: 0.04\n",
      "  Root Mean Squared Error: 0.19\n",
      "  R^2 Score: -0.00\n",
      "  Explained Variance Score: 0.01\n",
      "\n",
      "Overall Model Evaluation:\n",
      "  Mean Absolute Error: 0.31\n",
      "  Mean Squared Error: 0.32\n",
      "  Root Mean Squared Error: 0.47\n",
      "  Average R^2 Score: -0.04\n",
      "  Average Explained Variance Score: -0.00\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\n",
    "\n",
    "# Initialize the MultiOutputRegressor with SVR\n",
    "model_svr = MultiOutputRegressor(SVR(kernel='linear'))\n",
    "model_svr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_svr = model_svr.predict(X_test)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "mae_list = []\n",
    "mse_list = []\n",
    "rmse_list = []\n",
    "r2_list = []\n",
    "evs_list = []\n",
    "\n",
    "# Evaluate the model for each output\n",
    "for i, output_name in enumerate(y_test.columns):\n",
    "    mae = mean_absolute_error(y_test[output_name], y_pred_svr[:, i])\n",
    "    mse = mean_squared_error(y_test[output_name], y_pred_svr[:, i])\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test[output_name], y_pred_svr[:, i])\n",
    "    evs = explained_variance_score(y_test[output_name], y_pred_svr[:, i])\n",
    "\n",
    "    # Append metrics to lists\n",
    "    mae_list.append(mae)\n",
    "    mse_list.append(mse)\n",
    "    rmse_list.append(rmse)\n",
    "    r2_list.append(r2)\n",
    "    evs_list.append(evs)\n",
    "\n",
    "    print(f'SVR Output {output_name}:')\n",
    "    print(f'  Mean Absolute Error: {mae:.2f}')\n",
    "    print(f'  Mean Squared Error: {mse:.2f}')\n",
    "    print(f'  Root Mean Squared Error: {rmse:.2f}')\n",
    "    print(f'  R^2 Score: {r2:.2f}')\n",
    "    print(f'  Explained Variance Score: {evs:.2f}')\n",
    "    print()\n",
    "\n",
    "# Overall model evaluation\n",
    "overall_mae = np.mean(mae_list)\n",
    "overall_mse = np.mean(mse_list)\n",
    "overall_rmse = np.mean(rmse_list)\n",
    "overall_r2 = np.mean(r2_list)\n",
    "overall_evs = np.mean(evs_list)\n",
    "\n",
    "print(\"Overall Model Evaluation:\")\n",
    "print(f'  Mean Absolute Error: {overall_mae:.2f}')\n",
    "print(f'  Mean Squared Error: {overall_mse:.2f}')\n",
    "print(f'  Root Mean Squared Error: {overall_rmse:.2f}')\n",
    "print(f'  Average R^2 Score: {overall_r2:.2f}')\n",
    "print(f'  Average Explained Variance Score: {overall_evs:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1791s\u001b[0m 21ms/step - Anger_accuracy: 0.7845 - Anger_loss: 0.1245 - Anger_mae: 0.2347 - Disgust_accuracy: 0.8276 - Disgust_loss: 0.1012 - Disgust_mae: 0.1863 - Fear_accuracy: 0.8906 - Fear_loss: 0.0318 - Fear_mae: 0.0983 - Happy_accuracy: 0.3200 - Happy_loss: 0.3765 - Happy_mae: 0.4831 - Sad_accuracy: 0.7270 - Sad_loss: 0.1081 - Sad_mae: 0.2374 - Surprise_accuracy: 0.8930 - Surprise_loss: 0.0304 - Surprise_mae: 0.0894 - loss: 1.9417 - sentiment_output_loss: 1.1693 - sentiment_output_mae: 0.8253 - val_Anger_accuracy: 0.7847 - val_Anger_loss: 0.1226 - val_Anger_mae: 0.2361 - val_Disgust_accuracy: 0.8291 - val_Disgust_loss: 0.0981 - val_Disgust_mae: 0.1893 - val_Fear_accuracy: 0.8903 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.0988 - val_Happy_accuracy: 0.3302 - val_Happy_loss: 0.3715 - val_Happy_mae: 0.4752 - val_Sad_accuracy: 0.7269 - val_Sad_loss: 0.1072 - val_Sad_mae: 0.2356 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0303 - val_Surprise_mae: 0.0956 - val_loss: 1.8870 - val_sentiment_output_loss: 1.1255 - val_sentiment_output_mae: 0.8138\n",
      "Epoch 2/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1092s\u001b[0m 13ms/step - Anger_accuracy: 0.7837 - Anger_loss: 0.1218 - Anger_mae: 0.2308 - Disgust_accuracy: 0.8276 - Disgust_loss: 0.0985 - Disgust_mae: 0.1820 - Fear_accuracy: 0.8904 - Fear_loss: 0.0317 - Fear_mae: 0.0992 - Happy_accuracy: 0.3246 - Happy_loss: 0.3706 - Happy_mae: 0.4777 - Sad_accuracy: 0.7263 - Sad_loss: 0.1071 - Sad_mae: 0.2355 - Surprise_accuracy: 0.8928 - Surprise_loss: 0.0301 - Surprise_mae: 0.0907 - loss: 1.8823 - sentiment_output_loss: 1.1225 - sentiment_output_mae: 0.8108 - val_Anger_accuracy: 0.7845 - val_Anger_loss: 0.1218 - val_Anger_mae: 0.2268 - val_Disgust_accuracy: 0.8285 - val_Disgust_loss: 0.0975 - val_Disgust_mae: 0.1779 - val_Fear_accuracy: 0.8903 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.1010 - val_Happy_accuracy: 0.3438 - val_Happy_loss: 0.3714 - val_Happy_mae: 0.4719 - val_Sad_accuracy: 0.7267 - val_Sad_loss: 0.1070 - val_Sad_mae: 0.2384 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0918 - val_loss: 1.8745 - val_sentiment_output_loss: 1.1148 - val_sentiment_output_mae: 0.8075\n",
      "Epoch 3/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1414s\u001b[0m 17ms/step - Anger_accuracy: 0.7834 - Anger_loss: 0.1214 - Anger_mae: 0.2302 - Disgust_accuracy: 0.8272 - Disgust_loss: 0.0981 - Disgust_mae: 0.1813 - Fear_accuracy: 0.8903 - Fear_loss: 0.0317 - Fear_mae: 0.0993 - Happy_accuracy: 0.3254 - Happy_loss: 0.3689 - Happy_mae: 0.4760 - Sad_accuracy: 0.7266 - Sad_loss: 0.1067 - Sad_mae: 0.2350 - Surprise_accuracy: 0.8926 - Surprise_loss: 0.0303 - Surprise_mae: 0.0910 - loss: 1.8735 - sentiment_output_loss: 1.1163 - sentiment_output_mae: 0.8090 - val_Anger_accuracy: 0.7855 - val_Anger_loss: 0.1221 - val_Anger_mae: 0.2215 - val_Disgust_accuracy: 0.8282 - val_Disgust_loss: 0.0971 - val_Disgust_mae: 0.1787 - val_Fear_accuracy: 0.8903 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.0998 - val_Happy_accuracy: 0.3207 - val_Happy_loss: 0.3692 - val_Happy_mae: 0.4759 - val_Sad_accuracy: 0.7268 - val_Sad_loss: 0.1070 - val_Sad_mae: 0.2383 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0914 - val_loss: 1.8649 - val_sentiment_output_loss: 1.1075 - val_sentiment_output_mae: 0.8048\n",
      "Epoch 4/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1513s\u001b[0m 18ms/step - Anger_accuracy: 0.7835 - Anger_loss: 0.1211 - Anger_mae: 0.2295 - Disgust_accuracy: 0.8267 - Disgust_loss: 0.0982 - Disgust_mae: 0.1813 - Fear_accuracy: 0.8905 - Fear_loss: 0.0317 - Fear_mae: 0.0990 - Happy_accuracy: 0.3259 - Happy_loss: 0.3678 - Happy_mae: 0.4749 - Sad_accuracy: 0.7262 - Sad_loss: 0.1067 - Sad_mae: 0.2347 - Surprise_accuracy: 0.8924 - Surprise_loss: 0.0302 - Surprise_mae: 0.0910 - loss: 1.8652 - sentiment_output_loss: 1.1097 - sentiment_output_mae: 0.8066 - val_Anger_accuracy: 0.7830 - val_Anger_loss: 0.1216 - val_Anger_mae: 0.2251 - val_Disgust_accuracy: 0.8267 - val_Disgust_loss: 0.0973 - val_Disgust_mae: 0.1773 - val_Fear_accuracy: 0.8903 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.1029 - val_Happy_accuracy: 0.3314 - val_Happy_loss: 0.3684 - val_Happy_mae: 0.4722 - val_Sad_accuracy: 0.7265 - val_Sad_loss: 0.1070 - val_Sad_mae: 0.2308 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0886 - val_loss: 1.8617 - val_sentiment_output_loss: 1.1054 - val_sentiment_output_mae: 0.8052\n",
      "Epoch 5/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1257s\u001b[0m 15ms/step - Anger_accuracy: 0.7836 - Anger_loss: 0.1210 - Anger_mae: 0.2294 - Disgust_accuracy: 0.8272 - Disgust_loss: 0.0976 - Disgust_mae: 0.1804 - Fear_accuracy: 0.8901 - Fear_loss: 0.0317 - Fear_mae: 0.0993 - Happy_accuracy: 0.3263 - Happy_loss: 0.3675 - Happy_mae: 0.4747 - Sad_accuracy: 0.7265 - Sad_loss: 0.1067 - Sad_mae: 0.2345 - Surprise_accuracy: 0.8927 - Surprise_loss: 0.0301 - Surprise_mae: 0.0907 - loss: 1.8619 - sentiment_output_loss: 1.1072 - sentiment_output_mae: 0.8063 - val_Anger_accuracy: 0.7845 - val_Anger_loss: 0.1213 - val_Anger_mae: 0.2317 - val_Disgust_accuracy: 0.8270 - val_Disgust_loss: 0.0975 - val_Disgust_mae: 0.1877 - val_Fear_accuracy: 0.8902 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.0995 - val_Happy_accuracy: 0.3370 - val_Happy_loss: 0.3675 - val_Happy_mae: 0.4705 - val_Sad_accuracy: 0.7261 - val_Sad_loss: 0.1070 - val_Sad_mae: 0.2364 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0922 - val_loss: 1.8607 - val_sentiment_output_loss: 1.1053 - val_sentiment_output_mae: 0.8071\n",
      "Epoch 6/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m299s\u001b[0m 4ms/step - Anger_accuracy: 0.7834 - Anger_loss: 0.1208 - Anger_mae: 0.2291 - Disgust_accuracy: 0.8270 - Disgust_loss: 0.0980 - Disgust_mae: 0.1808 - Fear_accuracy: 0.8905 - Fear_loss: 0.0316 - Fear_mae: 0.0989 - Happy_accuracy: 0.3263 - Happy_loss: 0.3666 - Happy_mae: 0.4738 - Sad_accuracy: 0.7260 - Sad_loss: 0.1068 - Sad_mae: 0.2348 - Surprise_accuracy: 0.8926 - Surprise_loss: 0.0302 - Surprise_mae: 0.0908 - loss: 1.8579 - sentiment_output_loss: 1.1039 - sentiment_output_mae: 0.8054 - val_Anger_accuracy: 0.7798 - val_Anger_loss: 0.1222 - val_Anger_mae: 0.2344 - val_Disgust_accuracy: 0.8253 - val_Disgust_loss: 0.0974 - val_Disgust_mae: 0.1851 - val_Fear_accuracy: 0.8903 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.0991 - val_Happy_accuracy: 0.3358 - val_Happy_loss: 0.3683 - val_Happy_mae: 0.4704 - val_Sad_accuracy: 0.7269 - val_Sad_loss: 0.1068 - val_Sad_mae: 0.2375 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0915 - val_loss: 1.8623 - val_sentiment_output_loss: 1.1056 - val_sentiment_output_mae: 0.8077\n",
      "Epoch 7/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m297s\u001b[0m 4ms/step - Anger_accuracy: 0.7835 - Anger_loss: 0.1206 - Anger_mae: 0.2287 - Disgust_accuracy: 0.8264 - Disgust_loss: 0.0976 - Disgust_mae: 0.1805 - Fear_accuracy: 0.8904 - Fear_loss: 0.0316 - Fear_mae: 0.0989 - Happy_accuracy: 0.3256 - Happy_loss: 0.3672 - Happy_mae: 0.4742 - Sad_accuracy: 0.7261 - Sad_loss: 0.1066 - Sad_mae: 0.2343 - Surprise_accuracy: 0.8924 - Surprise_loss: 0.0303 - Surprise_mae: 0.0910 - loss: 1.8573 - sentiment_output_loss: 1.1035 - sentiment_output_mae: 0.8056 - val_Anger_accuracy: 0.7849 - val_Anger_loss: 0.1210 - val_Anger_mae: 0.2249 - val_Disgust_accuracy: 0.8287 - val_Disgust_loss: 0.0970 - val_Disgust_mae: 0.1755 - val_Fear_accuracy: 0.8902 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.1015 - val_Happy_accuracy: 0.3314 - val_Happy_loss: 0.3675 - val_Happy_mae: 0.4723 - val_Sad_accuracy: 0.7270 - val_Sad_loss: 0.1069 - val_Sad_mae: 0.2365 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0902 - val_loss: 1.8550 - val_sentiment_output_loss: 1.1006 - val_sentiment_output_mae: 0.8044\n",
      "Epoch 8/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m302s\u001b[0m 4ms/step - Anger_accuracy: 0.7837 - Anger_loss: 0.1203 - Anger_mae: 0.2283 - Disgust_accuracy: 0.8270 - Disgust_loss: 0.0973 - Disgust_mae: 0.1801 - Fear_accuracy: 0.8904 - Fear_loss: 0.0317 - Fear_mae: 0.0990 - Happy_accuracy: 0.3260 - Happy_loss: 0.3668 - Happy_mae: 0.4739 - Sad_accuracy: 0.7264 - Sad_loss: 0.1064 - Sad_mae: 0.2341 - Surprise_accuracy: 0.8931 - Surprise_loss: 0.0302 - Surprise_mae: 0.0906 - loss: 1.8549 - sentiment_output_loss: 1.1023 - sentiment_output_mae: 0.8053 - val_Anger_accuracy: 0.7842 - val_Anger_loss: 0.1210 - val_Anger_mae: 0.2308 - val_Disgust_accuracy: 0.8281 - val_Disgust_loss: 0.0969 - val_Disgust_mae: 0.1871 - val_Fear_accuracy: 0.8903 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.0989 - val_Happy_accuracy: 0.3532 - val_Happy_loss: 0.3689 - val_Happy_mae: 0.4644 - val_Sad_accuracy: 0.7262 - val_Sad_loss: 0.1074 - val_Sad_mae: 0.2462 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0926 - val_loss: 1.8616 - val_sentiment_output_loss: 1.1054 - val_sentiment_output_mae: 0.8094\n",
      "Epoch 9/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m321s\u001b[0m 4ms/step - Anger_accuracy: 0.7834 - Anger_loss: 0.1207 - Anger_mae: 0.2286 - Disgust_accuracy: 0.8265 - Disgust_loss: 0.0981 - Disgust_mae: 0.1811 - Fear_accuracy: 0.8903 - Fear_loss: 0.0317 - Fear_mae: 0.0990 - Happy_accuracy: 0.3257 - Happy_loss: 0.3662 - Happy_mae: 0.4734 - Sad_accuracy: 0.7261 - Sad_loss: 0.1067 - Sad_mae: 0.2345 - Surprise_accuracy: 0.8925 - Surprise_loss: 0.0302 - Surprise_mae: 0.0909 - loss: 1.8552 - sentiment_output_loss: 1.1015 - sentiment_output_mae: 0.8051 - val_Anger_accuracy: 0.7846 - val_Anger_loss: 0.1211 - val_Anger_mae: 0.2250 - val_Disgust_accuracy: 0.8292 - val_Disgust_loss: 0.0975 - val_Disgust_mae: 0.1732 - val_Fear_accuracy: 0.8903 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.0975 - val_Happy_accuracy: 0.3124 - val_Happy_loss: 0.3674 - val_Happy_mae: 0.4796 - val_Sad_accuracy: 0.7270 - val_Sad_loss: 0.1069 - val_Sad_mae: 0.2292 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0871 - val_loss: 1.8564 - val_sentiment_output_loss: 1.1014 - val_sentiment_output_mae: 0.8044\n",
      "Epoch 10/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m301s\u001b[0m 4ms/step - Anger_accuracy: 0.7830 - Anger_loss: 0.1204 - Anger_mae: 0.2285 - Disgust_accuracy: 0.8267 - Disgust_loss: 0.0979 - Disgust_mae: 0.1806 - Fear_accuracy: 0.8904 - Fear_loss: 0.0317 - Fear_mae: 0.0990 - Happy_accuracy: 0.3249 - Happy_loss: 0.3661 - Happy_mae: 0.4733 - Sad_accuracy: 0.7263 - Sad_loss: 0.1062 - Sad_mae: 0.2339 - Surprise_accuracy: 0.8927 - Surprise_loss: 0.0301 - Surprise_mae: 0.0906 - loss: 1.8518 - sentiment_output_loss: 1.0995 - sentiment_output_mae: 0.8045 - val_Anger_accuracy: 0.7851 - val_Anger_loss: 0.1210 - val_Anger_mae: 0.2265 - val_Disgust_accuracy: 0.8288 - val_Disgust_loss: 0.0970 - val_Disgust_mae: 0.1784 - val_Fear_accuracy: 0.8902 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.1024 - val_Happy_accuracy: 0.3149 - val_Happy_loss: 0.3663 - val_Happy_mae: 0.4758 - val_Sad_accuracy: 0.7270 - val_Sad_loss: 0.1068 - val_Sad_mae: 0.2342 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0933 - val_loss: 1.8511 - val_sentiment_output_loss: 1.0980 - val_sentiment_output_mae: 0.8028\n",
      "Epoch 11/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m300s\u001b[0m 4ms/step - Anger_accuracy: 0.7838 - Anger_loss: 0.1207 - Anger_mae: 0.2284 - Disgust_accuracy: 0.8267 - Disgust_loss: 0.0981 - Disgust_mae: 0.1808 - Fear_accuracy: 0.8903 - Fear_loss: 0.0317 - Fear_mae: 0.0991 - Happy_accuracy: 0.3242 - Happy_loss: 0.3656 - Happy_mae: 0.4729 - Sad_accuracy: 0.7261 - Sad_loss: 0.1063 - Sad_mae: 0.2340 - Surprise_accuracy: 0.8927 - Surprise_loss: 0.0303 - Surprise_mae: 0.0909 - loss: 1.8501 - sentiment_output_loss: 1.0973 - sentiment_output_mae: 0.8034 - val_Anger_accuracy: 0.7845 - val_Anger_loss: 0.1208 - val_Anger_mae: 0.2289 - val_Disgust_accuracy: 0.8278 - val_Disgust_loss: 0.0966 - val_Disgust_mae: 0.1826 - val_Fear_accuracy: 0.8902 - val_Fear_loss: 0.0318 - val_Fear_mae: 0.0976 - val_Happy_accuracy: 0.3035 - val_Happy_loss: 0.3671 - val_Happy_mae: 0.4827 - val_Sad_accuracy: 0.7270 - val_Sad_loss: 0.1068 - val_Sad_mae: 0.2293 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0924 - val_loss: 1.8494 - val_sentiment_output_loss: 1.0961 - val_sentiment_output_mae: 0.8036\n",
      "Epoch 12/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m309s\u001b[0m 4ms/step - Anger_accuracy: 0.7835 - Anger_loss: 0.1203 - Anger_mae: 0.2281 - Disgust_accuracy: 0.8267 - Disgust_loss: 0.0974 - Disgust_mae: 0.1801 - Fear_accuracy: 0.8905 - Fear_loss: 0.0316 - Fear_mae: 0.0988 - Happy_accuracy: 0.3264 - Happy_loss: 0.3654 - Happy_mae: 0.4727 - Sad_accuracy: 0.7261 - Sad_loss: 0.1066 - Sad_mae: 0.2342 - Surprise_accuracy: 0.8928 - Surprise_loss: 0.0299 - Surprise_mae: 0.0904 - loss: 1.8480 - sentiment_output_loss: 1.0968 - sentiment_output_mae: 0.8033 - val_Anger_accuracy: 0.7848 - val_Anger_loss: 0.1209 - val_Anger_mae: 0.2259 - val_Disgust_accuracy: 0.8279 - val_Disgust_loss: 0.0970 - val_Disgust_mae: 0.1806 - val_Fear_accuracy: 0.8902 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.1001 - val_Happy_accuracy: 0.3200 - val_Happy_loss: 0.3667 - val_Happy_mae: 0.4766 - val_Sad_accuracy: 0.7271 - val_Sad_loss: 0.1070 - val_Sad_mae: 0.2327 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0887 - val_loss: 1.8531 - val_sentiment_output_loss: 1.0994 - val_sentiment_output_mae: 0.8023\n",
      "Epoch 13/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 4ms/step - Anger_accuracy: 0.7835 - Anger_loss: 0.1202 - Anger_mae: 0.2280 - Disgust_accuracy: 0.8269 - Disgust_loss: 0.0973 - Disgust_mae: 0.1801 - Fear_accuracy: 0.8903 - Fear_loss: 0.0317 - Fear_mae: 0.0989 - Happy_accuracy: 0.3254 - Happy_loss: 0.3655 - Happy_mae: 0.4726 - Sad_accuracy: 0.7265 - Sad_loss: 0.1061 - Sad_mae: 0.2338 - Surprise_accuracy: 0.8927 - Surprise_loss: 0.0302 - Surprise_mae: 0.0907 - loss: 1.8476 - sentiment_output_loss: 1.0967 - sentiment_output_mae: 0.8034 - val_Anger_accuracy: 0.7838 - val_Anger_loss: 0.1206 - val_Anger_mae: 0.2302 - val_Disgust_accuracy: 0.8259 - val_Disgust_loss: 0.0966 - val_Disgust_mae: 0.1846 - val_Fear_accuracy: 0.8902 - val_Fear_loss: 0.0318 - val_Fear_mae: 0.0986 - val_Happy_accuracy: 0.3297 - val_Happy_loss: 0.3657 - val_Happy_mae: 0.4715 - val_Sad_accuracy: 0.7263 - val_Sad_loss: 0.1067 - val_Sad_mae: 0.2337 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0912 - val_loss: 1.8476 - val_sentiment_output_loss: 1.0961 - val_sentiment_output_mae: 0.8015\n",
      "Epoch 14/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m310s\u001b[0m 4ms/step - Anger_accuracy: 0.7831 - Anger_loss: 0.1203 - Anger_mae: 0.2282 - Disgust_accuracy: 0.8261 - Disgust_loss: 0.0977 - Disgust_mae: 0.1805 - Fear_accuracy: 0.8905 - Fear_loss: 0.0316 - Fear_mae: 0.0988 - Happy_accuracy: 0.3255 - Happy_loss: 0.3656 - Happy_mae: 0.4728 - Sad_accuracy: 0.7258 - Sad_loss: 0.1065 - Sad_mae: 0.2343 - Surprise_accuracy: 0.8925 - Surprise_loss: 0.0302 - Surprise_mae: 0.0909 - loss: 1.8485 - sentiment_output_loss: 1.0966 - sentiment_output_mae: 0.8035 - val_Anger_accuracy: 0.7845 - val_Anger_loss: 0.1209 - val_Anger_mae: 0.2335 - val_Disgust_accuracy: 0.8289 - val_Disgust_loss: 0.0975 - val_Disgust_mae: 0.1872 - val_Fear_accuracy: 0.8902 - val_Fear_loss: 0.0318 - val_Fear_mae: 0.0997 - val_Happy_accuracy: 0.3442 - val_Happy_loss: 0.3685 - val_Happy_mae: 0.4666 - val_Sad_accuracy: 0.7264 - val_Sad_loss: 0.1074 - val_Sad_mae: 0.2397 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0886 - val_loss: 1.8661 - val_sentiment_output_loss: 1.1099 - val_sentiment_output_mae: 0.8106\n",
      "Epoch 15/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 4ms/step - Anger_accuracy: 0.7835 - Anger_loss: 0.1203 - Anger_mae: 0.2280 - Disgust_accuracy: 0.8268 - Disgust_loss: 0.0975 - Disgust_mae: 0.1801 - Fear_accuracy: 0.8903 - Fear_loss: 0.0317 - Fear_mae: 0.0989 - Happy_accuracy: 0.3242 - Happy_loss: 0.3666 - Happy_mae: 0.4734 - Sad_accuracy: 0.7265 - Sad_loss: 0.1064 - Sad_mae: 0.2340 - Surprise_accuracy: 0.8928 - Surprise_loss: 0.0302 - Surprise_mae: 0.0907 - loss: 1.8498 - sentiment_output_loss: 1.0971 - sentiment_output_mae: 0.8036 - val_Anger_accuracy: 0.7849 - val_Anger_loss: 0.1213 - val_Anger_mae: 0.2260 - val_Disgust_accuracy: 0.8283 - val_Disgust_loss: 0.0971 - val_Disgust_mae: 0.1809 - val_Fear_accuracy: 0.8902 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.1007 - val_Happy_accuracy: 0.3394 - val_Happy_loss: 0.3667 - val_Happy_mae: 0.4680 - val_Sad_accuracy: 0.7258 - val_Sad_loss: 0.1077 - val_Sad_mae: 0.2438 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0900 - val_loss: 1.8566 - val_sentiment_output_loss: 1.1018 - val_sentiment_output_mae: 0.8077\n",
      "Epoch 16/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m312s\u001b[0m 4ms/step - Anger_accuracy: 0.7837 - Anger_loss: 0.1201 - Anger_mae: 0.2275 - Disgust_accuracy: 0.8270 - Disgust_loss: 0.0974 - Disgust_mae: 0.1796 - Fear_accuracy: 0.8899 - Fear_loss: 0.0317 - Fear_mae: 0.0991 - Happy_accuracy: 0.3247 - Happy_loss: 0.3654 - Happy_mae: 0.4726 - Sad_accuracy: 0.7263 - Sad_loss: 0.1066 - Sad_mae: 0.2343 - Surprise_accuracy: 0.8928 - Surprise_loss: 0.0301 - Surprise_mae: 0.0905 - loss: 1.8462 - sentiment_output_loss: 1.0948 - sentiment_output_mae: 0.8031 - val_Anger_accuracy: 0.7844 - val_Anger_loss: 0.1207 - val_Anger_mae: 0.2237 - val_Disgust_accuracy: 0.8275 - val_Disgust_loss: 0.0965 - val_Disgust_mae: 0.1770 - val_Fear_accuracy: 0.8902 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.0971 - val_Happy_accuracy: 0.3119 - val_Happy_loss: 0.3664 - val_Happy_mae: 0.4764 - val_Sad_accuracy: 0.7263 - val_Sad_loss: 0.1068 - val_Sad_mae: 0.2294 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0912 - val_loss: 1.8457 - val_sentiment_output_loss: 1.0932 - val_sentiment_output_mae: 0.8044\n",
      "Epoch 17/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m313s\u001b[0m 4ms/step - Anger_accuracy: 0.7834 - Anger_loss: 0.1202 - Anger_mae: 0.2279 - Disgust_accuracy: 0.8264 - Disgust_loss: 0.0975 - Disgust_mae: 0.1802 - Fear_accuracy: 0.8904 - Fear_loss: 0.0317 - Fear_mae: 0.0988 - Happy_accuracy: 0.3247 - Happy_loss: 0.3651 - Happy_mae: 0.4724 - Sad_accuracy: 0.7266 - Sad_loss: 0.1063 - Sad_mae: 0.2338 - Surprise_accuracy: 0.8927 - Surprise_loss: 0.0302 - Surprise_mae: 0.0906 - loss: 1.8475 - sentiment_output_loss: 1.0964 - sentiment_output_mae: 0.8039 - val_Anger_accuracy: 0.7827 - val_Anger_loss: 0.1206 - val_Anger_mae: 0.2260 - val_Disgust_accuracy: 0.8263 - val_Disgust_loss: 0.0966 - val_Disgust_mae: 0.1746 - val_Fear_accuracy: 0.8902 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.1009 - val_Happy_accuracy: 0.3326 - val_Happy_loss: 0.3666 - val_Happy_mae: 0.4724 - val_Sad_accuracy: 0.7270 - val_Sad_loss: 0.1068 - val_Sad_mae: 0.2337 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0889 - val_loss: 1.8465 - val_sentiment_output_loss: 1.0938 - val_sentiment_output_mae: 0.7998\n",
      "Epoch 18/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 4ms/step - Anger_accuracy: 0.7840 - Anger_loss: 0.1199 - Anger_mae: 0.2273 - Disgust_accuracy: 0.8269 - Disgust_loss: 0.0977 - Disgust_mae: 0.1799 - Fear_accuracy: 0.8904 - Fear_loss: 0.0318 - Fear_mae: 0.0990 - Happy_accuracy: 0.3263 - Happy_loss: 0.3648 - Happy_mae: 0.4721 - Sad_accuracy: 0.7265 - Sad_loss: 0.1060 - Sad_mae: 0.2338 - Surprise_accuracy: 0.8925 - Surprise_loss: 0.0302 - Surprise_mae: 0.0907 - loss: 1.8441 - sentiment_output_loss: 1.0938 - sentiment_output_mae: 0.8027 - val_Anger_accuracy: 0.7800 - val_Anger_loss: 0.1215 - val_Anger_mae: 0.2287 - val_Disgust_accuracy: 0.8275 - val_Disgust_loss: 0.0971 - val_Disgust_mae: 0.1746 - val_Fear_accuracy: 0.8902 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.1038 - val_Happy_accuracy: 0.3362 - val_Happy_loss: 0.3665 - val_Happy_mae: 0.4691 - val_Sad_accuracy: 0.7260 - val_Sad_loss: 0.1071 - val_Sad_mae: 0.2363 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0903 - val_loss: 1.8534 - val_sentiment_output_loss: 1.0992 - val_sentiment_output_mae: 0.8025\n",
      "Epoch 19/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m328s\u001b[0m 4ms/step - Anger_accuracy: 0.7835 - Anger_loss: 0.1202 - Anger_mae: 0.2278 - Disgust_accuracy: 0.8262 - Disgust_loss: 0.0975 - Disgust_mae: 0.1803 - Fear_accuracy: 0.8906 - Fear_loss: 0.0316 - Fear_mae: 0.0987 - Happy_accuracy: 0.3261 - Happy_loss: 0.3651 - Happy_mae: 0.4724 - Sad_accuracy: 0.7261 - Sad_loss: 0.1065 - Sad_mae: 0.2343 - Surprise_accuracy: 0.8928 - Surprise_loss: 0.0301 - Surprise_mae: 0.0906 - loss: 1.8458 - sentiment_output_loss: 1.0947 - sentiment_output_mae: 0.8031 - val_Anger_accuracy: 0.7819 - val_Anger_loss: 0.1213 - val_Anger_mae: 0.2273 - val_Disgust_accuracy: 0.8282 - val_Disgust_loss: 0.0968 - val_Disgust_mae: 0.1771 - val_Fear_accuracy: 0.8903 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.0981 - val_Happy_accuracy: 0.3039 - val_Happy_loss: 0.3662 - val_Happy_mae: 0.4789 - val_Sad_accuracy: 0.7269 - val_Sad_loss: 0.1069 - val_Sad_mae: 0.2284 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0922 - val_loss: 1.8501 - val_sentiment_output_loss: 1.0969 - val_sentiment_output_mae: 0.8033\n",
      "Epoch 20/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m316s\u001b[0m 4ms/step - Anger_accuracy: 0.7832 - Anger_loss: 0.1205 - Anger_mae: 0.2281 - Disgust_accuracy: 0.8264 - Disgust_loss: 0.0978 - Disgust_mae: 0.1803 - Fear_accuracy: 0.8902 - Fear_loss: 0.0317 - Fear_mae: 0.0989 - Happy_accuracy: 0.3267 - Happy_loss: 0.3652 - Happy_mae: 0.4724 - Sad_accuracy: 0.7261 - Sad_loss: 0.1063 - Sad_mae: 0.2338 - Surprise_accuracy: 0.8927 - Surprise_loss: 0.0301 - Surprise_mae: 0.0907 - loss: 1.8476 - sentiment_output_loss: 1.0959 - sentiment_output_mae: 0.8036 - val_Anger_accuracy: 0.7849 - val_Anger_loss: 0.1209 - val_Anger_mae: 0.2170 - val_Disgust_accuracy: 0.8283 - val_Disgust_loss: 0.0967 - val_Disgust_mae: 0.1727 - val_Fear_accuracy: 0.8903 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.1009 - val_Happy_accuracy: 0.3296 - val_Happy_loss: 0.3653 - val_Happy_mae: 0.4692 - val_Sad_accuracy: 0.7267 - val_Sad_loss: 0.1067 - val_Sad_mae: 0.2303 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0906 - val_loss: 1.8465 - val_sentiment_output_loss: 1.0947 - val_sentiment_output_mae: 0.8025\n",
      "Epoch 21/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m320s\u001b[0m 4ms/step - Anger_accuracy: 0.7834 - Anger_loss: 0.1199 - Anger_mae: 0.2276 - Disgust_accuracy: 0.8264 - Disgust_loss: 0.0976 - Disgust_mae: 0.1802 - Fear_accuracy: 0.8904 - Fear_loss: 0.0317 - Fear_mae: 0.0989 - Happy_accuracy: 0.3255 - Happy_loss: 0.3653 - Happy_mae: 0.4726 - Sad_accuracy: 0.7264 - Sad_loss: 0.1067 - Sad_mae: 0.2343 - Surprise_accuracy: 0.8927 - Surprise_loss: 0.0301 - Surprise_mae: 0.0906 - loss: 1.8478 - sentiment_output_loss: 1.0965 - sentiment_output_mae: 0.8038 - val_Anger_accuracy: 0.7853 - val_Anger_loss: 0.1208 - val_Anger_mae: 0.2258 - val_Disgust_accuracy: 0.8277 - val_Disgust_loss: 0.0969 - val_Disgust_mae: 0.1799 - val_Fear_accuracy: 0.8902 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.0996 - val_Happy_accuracy: 0.3184 - val_Happy_loss: 0.3662 - val_Happy_mae: 0.4741 - val_Sad_accuracy: 0.7269 - val_Sad_loss: 0.1068 - val_Sad_mae: 0.2343 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0904 - val_loss: 1.8509 - val_sentiment_output_loss: 1.0981 - val_sentiment_output_mae: 0.8029\n",
      "Epoch 22/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 4ms/step - Anger_accuracy: 0.7834 - Anger_loss: 0.1197 - Anger_mae: 0.2273 - Disgust_accuracy: 0.8270 - Disgust_loss: 0.0971 - Disgust_mae: 0.1795 - Fear_accuracy: 0.8904 - Fear_loss: 0.0317 - Fear_mae: 0.0988 - Happy_accuracy: 0.3260 - Happy_loss: 0.3650 - Happy_mae: 0.4723 - Sad_accuracy: 0.7265 - Sad_loss: 0.1064 - Sad_mae: 0.2341 - Surprise_accuracy: 0.8928 - Surprise_loss: 0.0302 - Surprise_mae: 0.0906 - loss: 1.8435 - sentiment_output_loss: 1.0933 - sentiment_output_mae: 0.8025 - val_Anger_accuracy: 0.7834 - val_Anger_loss: 0.1210 - val_Anger_mae: 0.2358 - val_Disgust_accuracy: 0.8258 - val_Disgust_loss: 0.0970 - val_Disgust_mae: 0.1803 - val_Fear_accuracy: 0.8903 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.0988 - val_Happy_accuracy: 0.3055 - val_Happy_loss: 0.3668 - val_Happy_mae: 0.4799 - val_Sad_accuracy: 0.7268 - val_Sad_loss: 0.1069 - val_Sad_mae: 0.2312 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0950 - val_loss: 1.8491 - val_sentiment_output_loss: 1.0954 - val_sentiment_output_mae: 0.8031\n",
      "Epoch 23/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m318s\u001b[0m 4ms/step - Anger_accuracy: 0.7837 - Anger_loss: 0.1200 - Anger_mae: 0.2274 - Disgust_accuracy: 0.8265 - Disgust_loss: 0.0978 - Disgust_mae: 0.1803 - Fear_accuracy: 0.8907 - Fear_loss: 0.0316 - Fear_mae: 0.0986 - Happy_accuracy: 0.3257 - Happy_loss: 0.3646 - Happy_mae: 0.4720 - Sad_accuracy: 0.7265 - Sad_loss: 0.1065 - Sad_mae: 0.2339 - Surprise_accuracy: 0.8926 - Surprise_loss: 0.0301 - Surprise_mae: 0.0907 - loss: 1.8460 - sentiment_output_loss: 1.0954 - sentiment_output_mae: 0.8034 - val_Anger_accuracy: 0.7851 - val_Anger_loss: 0.1206 - val_Anger_mae: 0.2259 - val_Disgust_accuracy: 0.8277 - val_Disgust_loss: 0.0968 - val_Disgust_mae: 0.1792 - val_Fear_accuracy: 0.8903 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.1004 - val_Happy_accuracy: 0.3179 - val_Happy_loss: 0.3654 - val_Happy_mae: 0.4756 - val_Sad_accuracy: 0.7271 - val_Sad_loss: 0.1069 - val_Sad_mae: 0.2302 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0898 - val_loss: 1.8449 - val_sentiment_output_loss: 1.0932 - val_sentiment_output_mae: 0.8005\n",
      "Epoch 24/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m322s\u001b[0m 4ms/step - Anger_accuracy: 0.7836 - Anger_loss: 0.1195 - Anger_mae: 0.2270 - Disgust_accuracy: 0.8267 - Disgust_loss: 0.0974 - Disgust_mae: 0.1797 - Fear_accuracy: 0.8902 - Fear_loss: 0.0318 - Fear_mae: 0.0992 - Happy_accuracy: 0.3252 - Happy_loss: 0.3652 - Happy_mae: 0.4725 - Sad_accuracy: 0.7263 - Sad_loss: 0.1065 - Sad_mae: 0.2341 - Surprise_accuracy: 0.8926 - Surprise_loss: 0.0304 - Surprise_mae: 0.0908 - loss: 1.8449 - sentiment_output_loss: 1.0943 - sentiment_output_mae: 0.8032 - val_Anger_accuracy: 0.7823 - val_Anger_loss: 0.1210 - val_Anger_mae: 0.2327 - val_Disgust_accuracy: 0.8256 - val_Disgust_loss: 0.0971 - val_Disgust_mae: 0.1862 - val_Fear_accuracy: 0.8903 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.0982 - val_Happy_accuracy: 0.3519 - val_Happy_loss: 0.3675 - val_Happy_mae: 0.4641 - val_Sad_accuracy: 0.7259 - val_Sad_loss: 0.1068 - val_Sad_mae: 0.2370 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0301 - val_Surprise_mae: 0.0920 - val_loss: 1.8540 - val_sentiment_output_loss: 1.0996 - val_sentiment_output_mae: 0.8078\n",
      "Epoch 25/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 4ms/step - Anger_accuracy: 0.7840 - Anger_loss: 0.1197 - Anger_mae: 0.2268 - Disgust_accuracy: 0.8266 - Disgust_loss: 0.0976 - Disgust_mae: 0.1799 - Fear_accuracy: 0.8904 - Fear_loss: 0.0317 - Fear_mae: 0.0989 - Happy_accuracy: 0.3260 - Happy_loss: 0.3647 - Happy_mae: 0.4719 - Sad_accuracy: 0.7261 - Sad_loss: 0.1063 - Sad_mae: 0.2340 - Surprise_accuracy: 0.8926 - Surprise_loss: 0.0303 - Surprise_mae: 0.0907 - loss: 1.8423 - sentiment_output_loss: 1.0920 - sentiment_output_mae: 0.8023 - val_Anger_accuracy: 0.7850 - val_Anger_loss: 0.1208 - val_Anger_mae: 0.2175 - val_Disgust_accuracy: 0.8278 - val_Disgust_loss: 0.0967 - val_Disgust_mae: 0.1739 - val_Fear_accuracy: 0.8902 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.1022 - val_Happy_accuracy: 0.3177 - val_Happy_loss: 0.3653 - val_Happy_mae: 0.4749 - val_Sad_accuracy: 0.7263 - val_Sad_loss: 0.1068 - val_Sad_mae: 0.2348 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0932 - val_loss: 1.8479 - val_sentiment_output_loss: 1.0963 - val_sentiment_output_mae: 0.8024\n",
      "Epoch 26/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 4ms/step - Anger_accuracy: 0.7839 - Anger_loss: 0.1200 - Anger_mae: 0.2272 - Disgust_accuracy: 0.8268 - Disgust_loss: 0.0974 - Disgust_mae: 0.1797 - Fear_accuracy: 0.8905 - Fear_loss: 0.0316 - Fear_mae: 0.0988 - Happy_accuracy: 0.3253 - Happy_loss: 0.3651 - Happy_mae: 0.4722 - Sad_accuracy: 0.7268 - Sad_loss: 0.1065 - Sad_mae: 0.2340 - Surprise_accuracy: 0.8928 - Surprise_loss: 0.0300 - Surprise_mae: 0.0904 - loss: 1.8427 - sentiment_output_loss: 1.0921 - sentiment_output_mae: 0.8021 - val_Anger_accuracy: 0.7849 - val_Anger_loss: 0.1208 - val_Anger_mae: 0.2238 - val_Disgust_accuracy: 0.8290 - val_Disgust_loss: 0.0967 - val_Disgust_mae: 0.1756 - val_Fear_accuracy: 0.8902 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.1007 - val_Happy_accuracy: 0.3241 - val_Happy_loss: 0.3656 - val_Happy_mae: 0.4735 - val_Sad_accuracy: 0.7267 - val_Sad_loss: 0.1067 - val_Sad_mae: 0.2341 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0889 - val_loss: 1.8435 - val_sentiment_output_loss: 1.0917 - val_sentiment_output_mae: 0.8017\n",
      "Epoch 27/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m384s\u001b[0m 4ms/step - Anger_accuracy: 0.7835 - Anger_loss: 0.1201 - Anger_mae: 0.2274 - Disgust_accuracy: 0.8269 - Disgust_loss: 0.0976 - Disgust_mae: 0.1798 - Fear_accuracy: 0.8902 - Fear_loss: 0.0316 - Fear_mae: 0.0988 - Happy_accuracy: 0.3259 - Happy_loss: 0.3646 - Happy_mae: 0.4717 - Sad_accuracy: 0.7261 - Sad_loss: 0.1064 - Sad_mae: 0.2338 - Surprise_accuracy: 0.8925 - Surprise_loss: 0.0302 - Surprise_mae: 0.0907 - loss: 1.8419 - sentiment_output_loss: 1.0914 - sentiment_output_mae: 0.8021 - val_Anger_accuracy: 0.7844 - val_Anger_loss: 0.1201 - val_Anger_mae: 0.2269 - val_Disgust_accuracy: 0.8276 - val_Disgust_loss: 0.0966 - val_Disgust_mae: 0.1787 - val_Fear_accuracy: 0.8902 - val_Fear_loss: 0.0318 - val_Fear_mae: 0.0995 - val_Happy_accuracy: 0.3492 - val_Happy_loss: 0.3669 - val_Happy_mae: 0.4652 - val_Sad_accuracy: 0.7268 - val_Sad_loss: 0.1067 - val_Sad_mae: 0.2341 - val_Surprise_accuracy: 0.8923 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0876 - val_loss: 1.8444 - val_sentiment_output_loss: 1.0919 - val_sentiment_output_mae: 0.7994\n",
      "Epoch 28/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m338s\u001b[0m 4ms/step - Anger_accuracy: 0.7839 - Anger_loss: 0.1199 - Anger_mae: 0.2270 - Disgust_accuracy: 0.8267 - Disgust_loss: 0.0974 - Disgust_mae: 0.1798 - Fear_accuracy: 0.8904 - Fear_loss: 0.0316 - Fear_mae: 0.0988 - Happy_accuracy: 0.3261 - Happy_loss: 0.3648 - Happy_mae: 0.4718 - Sad_accuracy: 0.7259 - Sad_loss: 0.1066 - Sad_mae: 0.2340 - Surprise_accuracy: 0.8927 - Surprise_loss: 0.0301 - Surprise_mae: 0.0904 - loss: 1.8426 - sentiment_output_loss: 1.0921 - sentiment_output_mae: 0.8022 - val_Anger_accuracy: 0.7838 - val_Anger_loss: 0.1200 - val_Anger_mae: 0.2304 - val_Disgust_accuracy: 0.8277 - val_Disgust_loss: 0.0966 - val_Disgust_mae: 0.1788 - val_Fear_accuracy: 0.8903 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.0995 - val_Happy_accuracy: 0.3147 - val_Happy_loss: 0.3652 - val_Happy_mae: 0.4736 - val_Sad_accuracy: 0.7266 - val_Sad_loss: 0.1066 - val_Sad_mae: 0.2339 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0887 - val_loss: 1.8404 - val_sentiment_output_loss: 1.0900 - val_sentiment_output_mae: 0.8010\n",
      "Epoch 29/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m336s\u001b[0m 4ms/step - Anger_accuracy: 0.7834 - Anger_loss: 0.1200 - Anger_mae: 0.2273 - Disgust_accuracy: 0.8265 - Disgust_loss: 0.0975 - Disgust_mae: 0.1798 - Fear_accuracy: 0.8909 - Fear_loss: 0.0315 - Fear_mae: 0.0984 - Happy_accuracy: 0.3263 - Happy_loss: 0.3634 - Happy_mae: 0.4709 - Sad_accuracy: 0.7262 - Sad_loss: 0.1066 - Sad_mae: 0.2341 - Surprise_accuracy: 0.8925 - Surprise_loss: 0.0304 - Surprise_mae: 0.0908 - loss: 1.8413 - sentiment_output_loss: 1.0918 - sentiment_output_mae: 0.8021 - val_Anger_accuracy: 0.7835 - val_Anger_loss: 0.1202 - val_Anger_mae: 0.2292 - val_Disgust_accuracy: 0.8275 - val_Disgust_loss: 0.0966 - val_Disgust_mae: 0.1811 - val_Fear_accuracy: 0.8902 - val_Fear_loss: 0.0318 - val_Fear_mae: 0.0975 - val_Happy_accuracy: 0.3379 - val_Happy_loss: 0.3647 - val_Happy_mae: 0.4682 - val_Sad_accuracy: 0.7264 - val_Sad_loss: 0.1067 - val_Sad_mae: 0.2338 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0889 - val_loss: 1.8430 - val_sentiment_output_loss: 1.0928 - val_sentiment_output_mae: 0.8063\n",
      "Epoch 30/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 4ms/step - Anger_accuracy: 0.7838 - Anger_loss: 0.1195 - Anger_mae: 0.2267 - Disgust_accuracy: 0.8266 - Disgust_loss: 0.0975 - Disgust_mae: 0.1797 - Fear_accuracy: 0.8905 - Fear_loss: 0.0317 - Fear_mae: 0.0988 - Happy_accuracy: 0.3259 - Happy_loss: 0.3647 - Happy_mae: 0.4716 - Sad_accuracy: 0.7264 - Sad_loss: 0.1065 - Sad_mae: 0.2337 - Surprise_accuracy: 0.8928 - Surprise_loss: 0.0301 - Surprise_mae: 0.0905 - loss: 1.8437 - sentiment_output_loss: 1.0937 - sentiment_output_mae: 0.8031 - val_Anger_accuracy: 0.7825 - val_Anger_loss: 0.1206 - val_Anger_mae: 0.2332 - val_Disgust_accuracy: 0.8277 - val_Disgust_loss: 0.0968 - val_Disgust_mae: 0.1791 - val_Fear_accuracy: 0.8903 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.0986 - val_Happy_accuracy: 0.3354 - val_Happy_loss: 0.3659 - val_Happy_mae: 0.4704 - val_Sad_accuracy: 0.7269 - val_Sad_loss: 0.1067 - val_Sad_mae: 0.2323 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0915 - val_loss: 1.8461 - val_sentiment_output_loss: 1.0941 - val_sentiment_output_mae: 0.8029\n",
      "Epoch 31/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 4ms/step - Anger_accuracy: 0.7840 - Anger_loss: 0.1192 - Anger_mae: 0.2265 - Disgust_accuracy: 0.8269 - Disgust_loss: 0.0968 - Disgust_mae: 0.1794 - Fear_accuracy: 0.8900 - Fear_loss: 0.0319 - Fear_mae: 0.0993 - Happy_accuracy: 0.3255 - Happy_loss: 0.3640 - Happy_mae: 0.4714 - Sad_accuracy: 0.7263 - Sad_loss: 0.1061 - Sad_mae: 0.2337 - Surprise_accuracy: 0.8928 - Surprise_loss: 0.0302 - Surprise_mae: 0.0907 - loss: 1.8362 - sentiment_output_loss: 1.0880 - sentiment_output_mae: 0.8008 - val_Anger_accuracy: 0.7844 - val_Anger_loss: 0.1201 - val_Anger_mae: 0.2209 - val_Disgust_accuracy: 0.8273 - val_Disgust_loss: 0.0963 - val_Disgust_mae: 0.1815 - val_Fear_accuracy: 0.8902 - val_Fear_loss: 0.0318 - val_Fear_mae: 0.0991 - val_Happy_accuracy: 0.3274 - val_Happy_loss: 0.3649 - val_Happy_mae: 0.4701 - val_Sad_accuracy: 0.7263 - val_Sad_loss: 0.1067 - val_Sad_mae: 0.2346 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0896 - val_loss: 1.8369 - val_sentiment_output_loss: 1.0869 - val_sentiment_output_mae: 0.8001\n",
      "Epoch 32/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m348s\u001b[0m 4ms/step - Anger_accuracy: 0.7832 - Anger_loss: 0.1197 - Anger_mae: 0.2269 - Disgust_accuracy: 0.8267 - Disgust_loss: 0.0974 - Disgust_mae: 0.1798 - Fear_accuracy: 0.8902 - Fear_loss: 0.0318 - Fear_mae: 0.0990 - Happy_accuracy: 0.3261 - Happy_loss: 0.3640 - Happy_mae: 0.4711 - Sad_accuracy: 0.7260 - Sad_loss: 0.1064 - Sad_mae: 0.2338 - Surprise_accuracy: 0.8928 - Surprise_loss: 0.0301 - Surprise_mae: 0.0904 - loss: 1.8394 - sentiment_output_loss: 1.0900 - sentiment_output_mae: 0.8018 - val_Anger_accuracy: 0.7831 - val_Anger_loss: 0.1202 - val_Anger_mae: 0.2290 - val_Disgust_accuracy: 0.8276 - val_Disgust_loss: 0.0964 - val_Disgust_mae: 0.1821 - val_Fear_accuracy: 0.8902 - val_Fear_loss: 0.0318 - val_Fear_mae: 0.0981 - val_Happy_accuracy: 0.3327 - val_Happy_loss: 0.3655 - val_Happy_mae: 0.4677 - val_Sad_accuracy: 0.7266 - val_Sad_loss: 0.1066 - val_Sad_mae: 0.2356 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0882 - val_loss: 1.8409 - val_sentiment_output_loss: 1.0901 - val_sentiment_output_mae: 0.8029\n",
      "Epoch 33/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m347s\u001b[0m 4ms/step - Anger_accuracy: 0.7839 - Anger_loss: 0.1196 - Anger_mae: 0.2268 - Disgust_accuracy: 0.8267 - Disgust_loss: 0.0974 - Disgust_mae: 0.1797 - Fear_accuracy: 0.8903 - Fear_loss: 0.0318 - Fear_mae: 0.0991 - Happy_accuracy: 0.3242 - Happy_loss: 0.3645 - Happy_mae: 0.4715 - Sad_accuracy: 0.7263 - Sad_loss: 0.1066 - Sad_mae: 0.2340 - Surprise_accuracy: 0.8928 - Surprise_loss: 0.0303 - Surprise_mae: 0.0906 - loss: 1.8420 - sentiment_output_loss: 1.0919 - sentiment_output_mae: 0.8025 - val_Anger_accuracy: 0.7840 - val_Anger_loss: 0.1203 - val_Anger_mae: 0.2279 - val_Disgust_accuracy: 0.8285 - val_Disgust_loss: 0.0967 - val_Disgust_mae: 0.1777 - val_Fear_accuracy: 0.8902 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.0995 - val_Happy_accuracy: 0.3201 - val_Happy_loss: 0.3652 - val_Happy_mae: 0.4755 - val_Sad_accuracy: 0.7269 - val_Sad_loss: 0.1068 - val_Sad_mae: 0.2316 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0906 - val_loss: 1.8462 - val_sentiment_output_loss: 1.0951 - val_sentiment_output_mae: 0.8016\n",
      "Epoch 34/50\n",
      "\u001b[1m83821/83821\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m342s\u001b[0m 4ms/step - Anger_accuracy: 0.7834 - Anger_loss: 0.1204 - Anger_mae: 0.2277 - Disgust_accuracy: 0.8263 - Disgust_loss: 0.0976 - Disgust_mae: 0.1800 - Fear_accuracy: 0.8908 - Fear_loss: 0.0315 - Fear_mae: 0.0984 - Happy_accuracy: 0.3274 - Happy_loss: 0.3639 - Happy_mae: 0.4712 - Sad_accuracy: 0.7258 - Sad_loss: 0.1067 - Sad_mae: 0.2343 - Surprise_accuracy: 0.8925 - Surprise_loss: 0.0303 - Surprise_mae: 0.0908 - loss: 1.8421 - sentiment_output_loss: 1.0917 - sentiment_output_mae: 0.8022 - val_Anger_accuracy: 0.7846 - val_Anger_loss: 0.1205 - val_Anger_mae: 0.2214 - val_Disgust_accuracy: 0.8291 - val_Disgust_loss: 0.0971 - val_Disgust_mae: 0.1687 - val_Fear_accuracy: 0.8903 - val_Fear_loss: 0.0319 - val_Fear_mae: 0.0969 - val_Happy_accuracy: 0.3100 - val_Happy_loss: 0.3659 - val_Happy_mae: 0.4778 - val_Sad_accuracy: 0.7255 - val_Sad_loss: 0.1068 - val_Sad_mae: 0.2339 - val_Surprise_accuracy: 0.8924 - val_Surprise_loss: 0.0302 - val_Surprise_mae: 0.0867 - val_loss: 1.8480 - val_sentiment_output_loss: 1.0957 - val_sentiment_output_mae: 0.8023\n",
      "Epoch 35/50\n",
      "\u001b[1m23513/83821\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:52\u001b[0m 4ms/step - Anger_accuracy: 0.7844 - Anger_loss: 0.1173 - Anger_mae: 0.2249 - Disgust_accuracy: 0.8265 - Disgust_loss: 0.0962 - Disgust_mae: 0.1787 - Fear_accuracy: 0.8902 - Fear_loss: 0.0317 - Fear_mae: 0.0988 - Happy_accuracy: 0.3258 - Happy_loss: 0.3643 - Happy_mae: 0.4714 - Sad_accuracy: 0.7254 - Sad_loss: 0.1070 - Sad_mae: 0.2342 - Surprise_accuracy: 0.8929 - Surprise_loss: 0.0298 - Surprise_mae: 0.0902 - loss: 1.8344 - sentiment_output_loss: 1.0881 - sentiment_output_mae: 0.8011"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import (mean_absolute_error, mean_squared_error, r2_score,\n",
    "                             explained_variance_score, accuracy_score, f1_score, precision_score, recall_score)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Reshape X for 1D CNN input (samples, timesteps, features)\n",
    "X_combined_cnn = X_combined.values.reshape(X_combined.shape[0], X_combined.shape[1], 1)\n",
    "\n",
    "# Split the combined data into training and testing sets\n",
    "X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(X_combined_cnn, y_combined, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build the CNN\n",
    "input_layer_cnn = layers.Input(shape=(X_train_cnn.shape[1], 1))\n",
    "conv_layer = layers.Conv1D(64, kernel_size=3, activation='relu')(input_layer_cnn)\n",
    "pool_layer = layers.MaxPooling1D(pool_size=2)(conv_layer)\n",
    "\n",
    "# Flatten and add shared fully connected layers\n",
    "flatten_layer = layers.Flatten()(pool_layer)\n",
    "shared_cnn = layers.Dense(128, activation='relu')(flatten_layer)\n",
    "shared_cnn = layers.Dense(64, activation='relu')(shared_cnn)\n",
    "\n",
    "# Sentiment output (first output)\n",
    "sentiment_output_cnn = layers.Dense(1, activation='tanh', name='sentiment_output')(shared_cnn)\n",
    "\n",
    "# Emotion outputs (remaining outputs)\n",
    "emotion_outputs_cnn = []\n",
    "for emotion_name in [\"Happy\", \"Sad\", \"Anger\", \"Surprise\", \"Disgust\", \"Fear\"]:\n",
    "    emotion_output_cnn = layers.Dense(1, activation='sigmoid', name=emotion_name)(shared_cnn)\n",
    "    emotion_outputs_cnn.append(emotion_output_cnn)\n",
    "\n",
    "# Create the model\n",
    "model_cnn = models.Model(inputs=input_layer_cnn, outputs=[sentiment_output_cnn] + emotion_outputs_cnn)\n",
    "\n",
    "# Compile the model with multiple metrics\n",
    "model_cnn.compile(optimizer='adam', loss='mse', \n",
    "                  metrics={'sentiment_output': ['mae'], **{name: ['mae', 'accuracy'] for name in [\"Happy\", \"Sad\", \"Anger\", \"Surprise\", \"Disgust\", \"Fear\"]}})\n",
    "\n",
    "# Train the model\n",
    "model_cnn.fit(\n",
    "    X_train_cnn,\n",
    "    [y_train_cnn['Sentiment']] + [y_train_cnn[emotion] for emotion in [\"Happy\", \"Sad\", \"Anger\", \"Surprise\", \"Disgust\", \"Fear\"]],\n",
    "    validation_data=(X_test_cnn, [y_test_cnn['Sentiment']] + [y_test_cnn[emotion] for emotion in [\"Happy\", \"Sad\", \"Anger\", \"Surprise\", \"Disgust\", \"Fear\"]]),\n",
    "    epochs=50,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Make predictions\n",
    "y_pred_cnn = model_cnn.predict(X_test_cnn)\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "mae_list = []\n",
    "mse_list = []\n",
    "rmse_list = []\n",
    "r2_list = []\n",
    "evs_list = []\n",
    "accuracy_list = []\n",
    "f1_list = []\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "\n",
    "# Evaluate the model for each output\n",
    "output_names = ['Sentiment', 'Happy', 'Sad', 'Anger', 'Surprise', 'Disgust', 'Fear']\n",
    "\n",
    "# Iterate over outputs\n",
    "for i, output_name in enumerate(output_names):\n",
    "    true_values = y_test_cnn[output_name].values.flatten()  # Get true values as 1D array\n",
    "    predicted_values = y_pred_cnn[i].flatten()  # Get predictions for current output and flatten if needed\n",
    "\n",
    "    if output_name == 'Sentiment':\n",
    "        # Classify sentiment as positive (1), neutral (0), or negative (-1)\n",
    "        true_classes = np.where(true_values > 0, 1, np.where(true_values < 0, -1, 0))\n",
    "        pred_classes = np.where(predicted_values > 0, 1, np.where(predicted_values < 0, -1, 0))\n",
    "\n",
    "        # Calculate regression metrics\n",
    "        mae = mean_absolute_error(true_values, predicted_values)\n",
    "        mse = mean_squared_error(true_values, predicted_values)\n",
    "        rmse = np.sqrt(mse)\n",
    "        r2 = r2_score(true_values, predicted_values)\n",
    "        evs = explained_variance_score(true_values, predicted_values)\n",
    "\n",
    "        # Calculate classification metrics (accuracy and F1-score)\n",
    "        accuracy = accuracy_score(true_classes, pred_classes)\n",
    "        f1 = f1_score(true_classes, pred_classes, average='weighted')  # Use weighted F1 for multi-class\n",
    "        precision = precision_score(true_classes, pred_classes, average='weighted')  # Weighted precision\n",
    "        recall = recall_score(true_classes, pred_classes, average='weighted')  # Weighted recall\n",
    "\n",
    "        # Append metrics to lists\n",
    "        mae_list.append(mae)\n",
    "        mse_list.append(mse)\n",
    "        rmse_list.append(rmse)\n",
    "        r2_list.append(r2)\n",
    "        evs_list.append(evs)\n",
    "        accuracy_list.append(accuracy)\n",
    "        f1_list.append(f1)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "\n",
    "        # Display metrics for sentiment output\n",
    "        print(f'CNN Output ({output_name}):')\n",
    "        print(f'  Mean Absolute Error: {mae:.2f}')\n",
    "        print(f'  Mean Squared Error: {mse:.2f}')\n",
    "        print(f'  Root Mean Squared Error: {rmse:.2f}')\n",
    "        print(f'  R^2 Score: {r2:.2f}')\n",
    "        print(f'  Explained Variance Score: {evs:.2f}')\n",
    "        print(f'  Accuracy: {accuracy:.2f}')\n",
    "        print(f'  F1 Score: {f1:.2f}')\n",
    "        print(f'  Precision: {precision:.2f}')\n",
    "        print(f'  Recall: {recall:.2f}\\n')\n",
    "\n",
    "    else:\n",
    "        # For emotion outputs, convert predictions to binary (0 or 1) based on a threshold (0.5)\n",
    "        binary_pred = (predicted_values > 0.5).astype(int)\n",
    "\n",
    "        # Calculate classification metrics\n",
    "        accuracy = accuracy_score(true_values, binary_pred)\n",
    "        f1 = f1_score(true_values, binary_pred)\n",
    "        precision = precision_score(true_values, binary_pred)\n",
    "        recall = recall_score(true_values, binary_pred)\n",
    "\n",
    "        # Append metrics to lists\n",
    "        accuracy_list.append(accuracy)\n",
    "        f1_list.append(f1)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "\n",
    "        # Display metrics for each emotion output\n",
    "        print(f'CNN Output ({output_name}):')\n",
    "        print(f'  Accuracy: {accuracy:.2f}')\n",
    "        print(f'  F1 Score: {f1:.2f}')\n",
    "        print(f'  Precision: {precision:.2f}')\n",
    "        print(f'  Recall: {recall:.2f}\\n')\n",
    "\n",
    "# Overall model evaluation for regression and classification\n",
    "overall_mae = np.mean(mae_list)\n",
    "overall_mse = np.mean(mse_list)\n",
    "overall_rmse = np.mean(rmse_list)\n",
    "overall_r2 = np.mean(r2_list)\n",
    "overall_evs = np.mean(evs_list)\n",
    "overall_accuracy = np.mean(accuracy_list)\n",
    "overall_f1 = np.mean(f1_list)\n",
    "overall_precision = np.mean(precision_list)\n",
    "overall_recall = np.mean(recall_list)\n",
    "\n",
    "print(\"Overall Model Evaluation (Regression):\")\n",
    "print(f'  Mean Absolute Error: {overall_mae:.2f}')\n",
    "print(f'  Mean Squared Error: {overall_mse:.2f}')\n",
    "print(f'  Root Mean Squared Error: {overall_rmse:.2f}')\n",
    "print(f'  Average R^2 Score: {overall_r2:.2f}')\n",
    "print(f'  Average Explained Variance Score: {overall_evs:.2f}\\n')\n",
    "\n",
    "print(\"Overall Model Evaluation (Classification):\")\n",
    "print(f'  Average Accuracy: {overall_accuracy:.2f}')\n",
    "print(f'  Average F1 Score: {overall_f1:.2f}')\n",
    "print(f'  Average Precision: {overall_precision:.2f}')\n",
    "print(f'  Average Recall: {overall_recall:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10478/10478\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1ms/step\n",
      "Type of y_pred_cnn: <class 'list'>\n",
      "Shapes of predictions:\n",
      "Output 0 shape: (335287, 1)\n",
      "Output 1 shape: (335287, 1)\n",
      "Output 2 shape: (335287, 1)\n",
      "Output 3 shape: (335287, 1)\n",
      "Output 4 shape: (335287, 1)\n",
      "Output 5 shape: (335287, 1)\n",
      "Output 6 shape: (335287, 1)\n",
      "Evaluating Sentiment:\n",
      "True values shape: (335287,), Predicted values shape: (335287,)\n",
      "CNN Output (Sentiment):\n",
      "  Mean Absolute Error: 0.81\n",
      "  Mean Squared Error: 1.11\n",
      "  Root Mean Squared Error: 1.05\n",
      "  R^2 Score: 0.09\n",
      "  Explained Variance Score: 0.09\n",
      "\n",
      "Evaluating Happy:\n",
      "True values shape: (335287,), Predicted values shape: (335287,)\n",
      "CNN Output (Happy):\n",
      "  Mean Absolute Error: 0.47\n",
      "  Mean Squared Error: 0.37\n",
      "  Root Mean Squared Error: 0.61\n",
      "  R^2 Score: 0.08\n",
      "  Explained Variance Score: 0.08\n",
      "\n",
      "Evaluating Sad:\n",
      "True values shape: (335287,), Predicted values shape: (335287,)\n",
      "CNN Output (Sad):\n",
      "  Mean Absolute Error: 0.24\n",
      "  Mean Squared Error: 0.11\n",
      "  Root Mean Squared Error: 0.33\n",
      "  R^2 Score: 0.03\n",
      "  Explained Variance Score: 0.03\n",
      "\n",
      "Evaluating Anger:\n",
      "True values shape: (335287,), Predicted values shape: (335287,)\n",
      "CNN Output (Anger):\n",
      "  Mean Absolute Error: 0.23\n",
      "  Mean Squared Error: 0.12\n",
      "  Root Mean Squared Error: 0.35\n",
      "  R^2 Score: 0.05\n",
      "  Explained Variance Score: 0.05\n",
      "\n",
      "Evaluating Surprise:\n",
      "True values shape: (335287,), Predicted values shape: (335287,)\n",
      "CNN Output (Surprise):\n",
      "  Mean Absolute Error: 0.09\n",
      "  Mean Squared Error: 0.03\n",
      "  Root Mean Squared Error: 0.17\n",
      "  R^2 Score: 0.01\n",
      "  Explained Variance Score: 0.01\n",
      "\n",
      "Evaluating Disgust:\n",
      "True values shape: (335287,), Predicted values shape: (335287,)\n",
      "CNN Output (Disgust):\n",
      "  Mean Absolute Error: 0.18\n",
      "  Mean Squared Error: 0.10\n",
      "  Root Mean Squared Error: 0.31\n",
      "  R^2 Score: 0.06\n",
      "  Explained Variance Score: 0.06\n",
      "\n",
      "Evaluating Fear:\n",
      "True values shape: (335287,), Predicted values shape: (335287,)\n",
      "CNN Output (Fear):\n",
      "  Mean Absolute Error: 0.10\n",
      "  Mean Squared Error: 0.03\n",
      "  Root Mean Squared Error: 0.18\n",
      "  R^2 Score: 0.00\n",
      "  Explained Variance Score: 0.00\n",
      "\n",
      "Overall Model Evaluation:\n",
      "  Mean Absolute Error: 0.30\n",
      "  Mean Squared Error: 0.27\n",
      "  Root Mean Squared Error: 0.43\n",
      "  Average R^2 Score: 0.05\n",
      "  Average Explained Variance Score: 0.05\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "y_pred_cnn = model_cnn.predict(X_test_cnn)\n",
    "\n",
    "# Check the type and shapes of predictions\n",
    "print(\"Type of y_pred_cnn:\", type(y_pred_cnn))  # This should show it's a list\n",
    "print(\"Shapes of predictions:\")\n",
    "for i, pred in enumerate(y_pred_cnn):\n",
    "    print(f\"Output {i} shape: {pred.shape}\")\n",
    "\n",
    "# Initialize lists to store evaluation metrics\n",
    "mae_list = []\n",
    "mse_list = []\n",
    "rmse_list = []\n",
    "r2_list = []\n",
    "evs_list = []\n",
    "\n",
    "# Evaluate the model for each output\n",
    "output_names = ['Sentiment', 'Happy', 'Sad', 'Anger', 'Surprise', 'Disgust', 'Fear']\n",
    "\n",
    "# Iterate over outputs\n",
    "for i, output_name in enumerate(output_names):\n",
    "    true_values = y_test_cnn[output_name].values.flatten()  # Get true values as 1D array\n",
    "    predicted_values = y_pred_cnn[i].flatten()  # Get predictions for current output and flatten if needed\n",
    "\n",
    "    # Check the shapes of true and predicted values\n",
    "    print(f\"Evaluating {output_name}:\")\n",
    "    print(f\"True values shape: {true_values.shape}, Predicted values shape: {predicted_values.shape}\")\n",
    "\n",
    "    # Calculate metrics\n",
    "    mae = mean_absolute_error(true_values, predicted_values)\n",
    "    mse = mean_squared_error(true_values, predicted_values)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(true_values, predicted_values)\n",
    "    evs = explained_variance_score(true_values, predicted_values)\n",
    "\n",
    "    # Append metrics to lists\n",
    "    mae_list.append(mae)\n",
    "    mse_list.append(mse)\n",
    "    rmse_list.append(rmse)\n",
    "    r2_list.append(r2)\n",
    "    evs_list.append(evs)\n",
    "\n",
    "    # Display metrics for each output\n",
    "    print(f'CNN Output ({output_name}):')\n",
    "    print(f'  Mean Absolute Error: {mae:.2f}')\n",
    "    print(f'  Mean Squared Error: {mse:.2f}')\n",
    "    print(f'  Root Mean Squared Error: {rmse:.2f}')\n",
    "    print(f'  R^2 Score: {r2:.2f}')\n",
    "    print(f'  Explained Variance Score: {evs:.2f}')\n",
    "    print()\n",
    "\n",
    "# Overall model evaluation\n",
    "overall_mae = np.mean(mae_list)\n",
    "overall_mse = np.mean(mse_list)\n",
    "overall_rmse = np.mean(rmse_list)\n",
    "overall_r2 = np.mean(r2_list)\n",
    "overall_evs = np.mean(evs_list)\n",
    "\n",
    "print(\"Overall Model Evaluation:\")\n",
    "print(f'  Mean Absolute Error: {overall_mae:.2f}')\n",
    "print(f'  Mean Squared Error: {overall_mse:.2f}')\n",
    "print(f'  Root Mean Squared Error: {overall_rmse:.2f}')\n",
    "print(f'  Average R^2 Score: {overall_r2:.2f}')\n",
    "print(f'  Average Explained Variance Score: {overall_evs:.2f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting lightgbm\n",
      "  Downloading lightgbm-4.5.0-py3-none-win_amd64.whl.metadata (17 kB)\n",
      "Collecting catboost\n",
      "  Downloading catboost-1.2.7-cp312-cp312-win_amd64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lightgbm) (2.0.2)\n",
      "Requirement already satisfied: scipy in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from lightgbm) (1.14.1)\n",
      "Collecting graphviz (from catboost)\n",
      "  Downloading graphviz-0.20.3-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting matplotlib (from catboost)\n",
      "  Downloading matplotlib-3.9.2-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
      "Collecting numpy>=1.17.0 (from lightgbm)\n",
      "  Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (2.2.3)\n",
      "Collecting plotly (from catboost)\n",
      "  Downloading plotly-5.24.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: six in c:\\users\\deeps\\appdata\\roaming\\python\\python312\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\deeps\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib->catboost)\n",
      "  Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib->catboost)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib->catboost)\n",
      "  Downloading fonttools-4.55.0-cp312-cp312-win_amd64.whl.metadata (167 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib->catboost)\n",
      "  Downloading kiwisolver-1.4.7-cp312-cp312-win_amd64.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\deeps\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (24.1)\n",
      "Collecting pillow>=8 (from matplotlib->catboost)\n",
      "  Downloading pillow-11.0.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib->catboost)\n",
      "  Downloading pyparsing-3.2.0-py3-none-any.whl.metadata (5.0 kB)\n",
      "Collecting tenacity>=6.2.0 (from plotly->catboost)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Downloading lightgbm-4.5.0-py3-none-win_amd64.whl (1.4 MB)\n",
      "   ---------------------------------------- 0.0/1.4 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.4/1.4 MB 9.5 MB/s eta 0:00:00\n",
      "Downloading catboost-1.2.7-cp312-cp312-win_amd64.whl (101.7 MB)\n",
      "   ---------------------------------------- 0.0/101.7 MB ? eta -:--:--\n",
      "    --------------------------------------- 1.8/101.7 MB 10.1 MB/s eta 0:00:10\n",
      "   - -------------------------------------- 4.2/101.7 MB 11.0 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 6.8/101.7 MB 11.3 MB/s eta 0:00:09\n",
      "   --- ------------------------------------ 9.7/101.7 MB 11.8 MB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 12.3/101.7 MB 12.3 MB/s eta 0:00:08\n",
      "   ----- ---------------------------------- 15.2/101.7 MB 12.6 MB/s eta 0:00:07\n",
      "   ------- -------------------------------- 18.4/101.7 MB 12.9 MB/s eta 0:00:07\n",
      "   -------- ------------------------------- 21.2/101.7 MB 13.2 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 24.4/101.7 MB 13.4 MB/s eta 0:00:06\n",
      "   ---------- ----------------------------- 27.5/101.7 MB 13.6 MB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 30.4/101.7 MB 13.8 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 33.8/101.7 MB 13.9 MB/s eta 0:00:05\n",
      "   -------------- ------------------------- 37.0/101.7 MB 14.1 MB/s eta 0:00:05\n",
      "   --------------- ------------------------ 40.1/101.7 MB 14.2 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 43.5/101.7 MB 14.3 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 47.2/101.7 MB 14.5 MB/s eta 0:00:04\n",
      "   ------------------- -------------------- 50.3/101.7 MB 14.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 53.7/101.7 MB 14.6 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 57.1/101.7 MB 14.7 MB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 60.6/101.7 MB 14.8 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 64.0/101.7 MB 14.9 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 67.4/101.7 MB 14.9 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 70.5/101.7 MB 14.9 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 73.9/101.7 MB 15.0 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 77.1/101.7 MB 15.0 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 80.5/101.7 MB 15.1 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 83.6/101.7 MB 15.1 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 87.0/101.7 MB 15.2 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 90.2/101.7 MB 15.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 93.6/101.7 MB 15.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 97.0/101.7 MB 15.2 MB/s eta 0:00:01\n",
      "   --------------------------------------  100.1/101.7 MB 15.3 MB/s eta 0:00:01\n",
      "   --------------------------------------- 101.7/101.7 MB 15.1 MB/s eta 0:00:00\n",
      "Downloading numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "   ---------------------------------------- 0.0/15.5 MB ? eta -:--:--\n",
      "   -------- ------------------------------- 3.1/15.5 MB 16.8 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 6.3/15.5 MB 16.1 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 9.7/15.5 MB 16.3 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 12.8/15.5 MB 16.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.5/15.5 MB 16.0 MB/s eta 0:00:00\n",
      "Downloading graphviz-0.20.3-py3-none-any.whl (47 kB)\n",
      "Downloading matplotlib-3.9.2-cp312-cp312-win_amd64.whl (7.8 MB)\n",
      "   ---------------------------------------- 0.0/7.8 MB ? eta -:--:--\n",
      "   ---------------- ----------------------- 3.1/7.8 MB 16.8 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 6.3/7.8 MB 16.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.8/7.8 MB 15.1 MB/s eta 0:00:00\n",
      "Downloading plotly-5.24.1-py3-none-any.whl (19.1 MB)\n",
      "   ---------------------------------------- 0.0/19.1 MB ? eta -:--:--\n",
      "   ------ --------------------------------- 2.9/19.1 MB 15.2 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 6.0/19.1 MB 15.4 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 9.2/19.1 MB 15.4 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 12.3/19.1 MB 15.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 15.5/19.1 MB 15.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------  18.9/19.1 MB 15.5 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 19.1/19.1 MB 15.2 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.3.1-cp312-cp312-win_amd64.whl (220 kB)\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.2/2.2 MB 15.5 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.7-cp312-cp312-win_amd64.whl (55 kB)\n",
      "Downloading pillow-11.0.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "   ---------------------------------------- 0.0/2.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.6/2.6 MB 14.8 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.2.0-py3-none-any.whl (106 kB)\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: tenacity, pyparsing, pillow, numpy, kiwisolver, graphviz, fonttools, cycler, plotly, contourpy, matplotlib, lightgbm, catboost\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 2.0.2\n",
      "    Uninstalling numpy-2.0.2:\n",
      "      Successfully uninstalled numpy-2.0.2\n",
      "Successfully installed catboost-1.2.7 contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.0 graphviz-0.20.3 kiwisolver-1.4.7 lightgbm-4.5.0 matplotlib-3.9.2 numpy-1.26.4 pillow-11.0.0 plotly-5.24.1 pyparsing-3.2.0 tenacity-9.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script f2py.exe is installed in 'c:\\Users\\deeps\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\deeps\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~umpy.libs'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\deeps\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~umpy'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: The scripts fonttools.exe, pyftmerge.exe, pyftsubset.exe and ttx.exe are installed in 'c:\\Users\\deeps\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install lightgbm catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: catboost in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (1.2.7)\n",
      "Requirement already satisfied: graphviz in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (3.9.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.16.0 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (2.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (1.14.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in c:\\users\\deeps\\appdata\\roaming\\python\\python312\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\deeps\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\deeps\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (3.2.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from plotly->catboost) (9.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: numpy 1.26.4\n",
      "Uninstalling numpy-1.26.4:\n",
      "  Successfully uninstalled numpy-1.26.4\n",
      "Found existing installation: catboost 1.2.7\n",
      "Uninstalling catboost-1.2.7:\n",
      "  Successfully uninstalled catboost-1.2.7\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\deeps\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~atboost'.\n",
      "You can safely remove it manually.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting catboost\n",
      "  Using cached catboost-1.2.7-cp312-cp312-win_amd64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: graphviz in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (0.20.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (3.9.2)\n",
      "Collecting numpy\n",
      "  Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl.metadata (61 kB)\n",
      "Requirement already satisfied: pandas>=0.24 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (2.2.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (1.14.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from catboost) (5.24.1)\n",
      "Requirement already satisfied: six in c:\\users\\deeps\\appdata\\roaming\\python\\python312\\site-packages (from catboost) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\deeps\\appdata\\roaming\\python\\python312\\site-packages (from pandas>=0.24->catboost) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from pandas>=0.24->catboost) (2024.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (4.55.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (1.4.7)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\deeps\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib->catboost) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from matplotlib->catboost) (3.2.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\deeps\\appdata\\local\\programs\\python\\python312\\lib\\site-packages (from plotly->catboost) (9.0.0)\n",
      "Using cached catboost-1.2.7-cp312-cp312-win_amd64.whl (101.7 MB)\n",
      "Using cached numpy-1.26.4-cp312-cp312-win_amd64.whl (15.5 MB)\n",
      "Installing collected packages: numpy, catboost\n",
      "Successfully installed catboost-1.2.7 numpy-1.26.4\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Retrying (Retry(total=4, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002905DF015E0>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')': /packages/a6/84/fa11dad3404b7634aaab50733581ce11e5350383311ea7a7010f464c0170/numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata\n",
      "  WARNING: Retrying (Retry(total=3, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002905DF00BF0>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')': /packages/a6/84/fa11dad3404b7634aaab50733581ce11e5350383311ea7a7010f464c0170/numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata\n",
      "  WARNING: Retrying (Retry(total=2, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002905DF01040>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')': /packages/a6/84/fa11dad3404b7634aaab50733581ce11e5350383311ea7a7010f464c0170/numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata\n",
      "  WARNING: Retrying (Retry(total=1, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002905DF013D0>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')': /packages/a6/84/fa11dad3404b7634aaab50733581ce11e5350383311ea7a7010f464c0170/numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata\n",
      "  WARNING: Retrying (Retry(total=0, connect=None, read=None, redirect=None, status=None)) after connection broken by 'NewConnectionError('<pip._vendor.urllib3.connection.HTTPSConnection object at 0x000002905DF01A60>: Failed to establish a new connection: [Errno 11002] getaddrinfo failed')': /packages/a6/84/fa11dad3404b7634aaab50733581ce11e5350383311ea7a7010f464c0170/numpy-2.1.3-cp312-cp312-win_amd64.whl.metadata\n",
      "  WARNING: The script f2py.exe is installed in 'c:\\Users\\deeps\\AppData\\Local\\Programs\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip uninstall numpy catboost -y\n",
    "%pip install numpy catboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy version: 1.26.4\n",
      "CatBoost version: 1.2.7\n"
     ]
    }
   ],
   "source": [
    "import numpy\n",
    "import catboost\n",
    "print(\"NumPy version:\", numpy.__version__)\n",
    "print(\"CatBoost version:\", catboost.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AdaBoost ===\n",
      "\n",
      "Sentiment Metrics:\n",
      "  MAE: 0.83\n",
      "  MSE: 1.19\n",
      "  RMSE: 1.09\n",
      "  R2: 0.02\n",
      "  Accuracy: 0.61\n",
      "  F1: 0.46\n",
      "  Precision: 0.37\n",
      "  Recall: 0.61\n",
      "\n",
      "Happy Metrics:\n",
      "  MAE: 0.60\n",
      "  MSE: 0.47\n",
      "  RMSE: 0.69\n",
      "  R2: -0.17\n",
      "  Accuracy: 0.37\n",
      "  F1: 0.20\n",
      "  Precision: 0.69\n",
      "  Recall: 0.37\n",
      "\n",
      "Sad Metrics:\n",
      "  MAE: 0.35\n",
      "  MSE: 0.16\n",
      "  RMSE: 0.40\n",
      "  R2: -0.47\n",
      "  Accuracy: 0.74\n",
      "  F1: 0.75\n",
      "  Precision: 0.77\n",
      "  Recall: 0.74\n",
      "\n",
      "Anger Metrics:\n",
      "  MAE: 0.41\n",
      "  MSE: 0.21\n",
      "  RMSE: 0.46\n",
      "  R2: -0.66\n",
      "  Accuracy: 0.55\n",
      "  F1: 0.63\n",
      "  Precision: 0.79\n",
      "  Recall: 0.55\n",
      "\n",
      "Surprise Metrics:\n",
      "  MAE: 0.37\n",
      "  MSE: 0.16\n",
      "  RMSE: 0.39\n",
      "  R2: -4.13\n",
      "  Accuracy: 0.78\n",
      "  F1: 0.85\n",
      "  Precision: 0.94\n",
      "  Recall: 0.78\n",
      "\n",
      "Disgust Metrics:\n",
      "  MAE: 0.41\n",
      "  MSE: 0.21\n",
      "  RMSE: 0.46\n",
      "  R2: -1.00\n",
      "  Accuracy: 0.72\n",
      "  F1: 0.77\n",
      "  Precision: 0.85\n",
      "  Recall: 0.72\n",
      "\n",
      "Fear Metrics:\n",
      "  MAE: 0.23\n",
      "  MSE: 0.06\n",
      "  RMSE: 0.25\n",
      "  R2: -0.90\n",
      "  Accuracy: 0.95\n",
      "  F1: 0.93\n",
      "  Precision: 0.92\n",
      "  Recall: 0.95\n",
      "\n",
      "Overall Metrics (Average and STD):\n",
      "  MAE - Average: 0.46, STD: 0.18\n",
      "  MSE - Average: 0.35, STD: 0.36\n",
      "  RMSE - Average: 0.53, STD: 0.26\n",
      "  R2 - Average: -1.04, STD: 1.30\n",
      "  Accuracy - Average: 0.68, STD: 0.17\n",
      "  F1 - Average: 0.66, STD: 0.23\n",
      "  Precision - Average: 0.76, STD: 0.18\n",
      "  Recall - Average: 0.68, STD: 0.17\n",
      "\n",
      "=== XGBoost ===\n",
      "\n",
      "Sentiment Metrics:\n",
      "  MAE: 0.80\n",
      "  MSE: 1.09\n",
      "  RMSE: 1.04\n",
      "  R2: 0.10\n",
      "  Accuracy: 0.62\n",
      "  F1: 0.57\n",
      "  Precision: 0.60\n",
      "  Recall: 0.62\n",
      "\n",
      "Happy Metrics:\n",
      "  MAE: 0.47\n",
      "  MSE: 0.36\n",
      "  RMSE: 0.60\n",
      "  R2: 0.11\n",
      "  Accuracy: 0.62\n",
      "  F1: 0.62\n",
      "  Precision: 0.64\n",
      "  Recall: 0.62\n",
      "\n",
      "Sad Metrics:\n",
      "  MAE: 0.23\n",
      "  MSE: 0.10\n",
      "  RMSE: 0.32\n",
      "  R2: 0.07\n",
      "  Accuracy: 0.86\n",
      "  F1: 0.80\n",
      "  Precision: 0.83\n",
      "  Recall: 0.86\n",
      "\n",
      "Anger Metrics:\n",
      "  MAE: 0.22\n",
      "  MSE: 0.12\n",
      "  RMSE: 0.34\n",
      "  R2: 0.08\n",
      "  Accuracy: 0.88\n",
      "  F1: 0.83\n",
      "  Precision: 0.85\n",
      "  Recall: 0.88\n",
      "\n",
      "Surprise Metrics:\n",
      "  MAE: 0.09\n",
      "  MSE: 0.03\n",
      "  RMSE: 0.17\n",
      "  R2: 0.02\n",
      "  Accuracy: 0.97\n",
      "  F1: 0.95\n",
      "  Precision: 0.95\n",
      "  Recall: 0.97\n",
      "\n",
      "Disgust Metrics:\n",
      "  MAE: 0.18\n",
      "  MSE: 0.09\n",
      "  RMSE: 0.31\n",
      "  R2: 0.09\n",
      "  Accuracy: 0.91\n",
      "  F1: 0.88\n",
      "  Precision: 0.89\n",
      "  Recall: 0.91\n",
      "\n",
      "Fear Metrics:\n",
      "  MAE: 0.10\n",
      "  MSE: 0.03\n",
      "  RMSE: 0.18\n",
      "  R2: 0.03\n",
      "  Accuracy: 0.95\n",
      "  F1: 0.93\n",
      "  Precision: 0.94\n",
      "  Recall: 0.95\n",
      "\n",
      "Overall Metrics (Average and STD):\n",
      "  MAE - Average: 0.30, STD: 0.24\n",
      "  MSE - Average: 0.26, STD: 0.35\n",
      "  RMSE - Average: 0.42, STD: 0.29\n",
      "  R2 - Average: 0.07, STD: 0.03\n",
      "  Accuracy - Average: 0.83, STD: 0.14\n",
      "  F1 - Average: 0.80, STD: 0.14\n",
      "  Precision - Average: 0.81, STD: 0.13\n",
      "  Recall - Average: 0.83, STD: 0.14\n",
      "\n",
      "=== LightGBM ===\n",
      "\n",
      "Sentiment Metrics:\n",
      "  MAE: 0.81\n",
      "  MSE: 1.11\n",
      "  RMSE: 1.06\n",
      "  R2: 0.08\n",
      "  Accuracy: 0.62\n",
      "  F1: 0.54\n",
      "  Precision: 0.60\n",
      "  Recall: 0.62\n",
      "\n",
      "Happy Metrics:\n",
      "  MAE: 0.47\n",
      "  MSE: 0.36\n",
      "  RMSE: 0.60\n",
      "  R2: 0.10\n",
      "  Accuracy: 0.61\n",
      "  F1: 0.62\n",
      "  Precision: 0.63\n",
      "  Recall: 0.61\n",
      "\n",
      "Sad Metrics:\n",
      "  MAE: 0.23\n",
      "  MSE: 0.10\n",
      "  RMSE: 0.32\n",
      "  R2: 0.05\n",
      "  Accuracy: 0.86\n",
      "  F1: 0.79\n",
      "  Precision: 0.84\n",
      "  Recall: 0.86\n",
      "\n",
      "Anger Metrics:\n",
      "  MAE: 0.23\n",
      "  MSE: 0.12\n",
      "  RMSE: 0.34\n",
      "  R2: 0.06\n",
      "  Accuracy: 0.88\n",
      "  F1: 0.82\n",
      "  Precision: 0.86\n",
      "  Recall: 0.88\n",
      "\n",
      "Surprise Metrics:\n",
      "  MAE: 0.09\n",
      "  MSE: 0.03\n",
      "  RMSE: 0.17\n",
      "  R2: 0.02\n",
      "  Accuracy: 0.97\n",
      "  F1: 0.95\n",
      "  Precision: 0.95\n",
      "  Recall: 0.97\n",
      "\n",
      "Disgust Metrics:\n",
      "  MAE: 0.18\n",
      "  MSE: 0.10\n",
      "  RMSE: 0.31\n",
      "  R2: 0.08\n",
      "  Accuracy: 0.91\n",
      "  F1: 0.87\n",
      "  Precision: 0.89\n",
      "  Recall: 0.91\n",
      "\n",
      "Fear Metrics:\n",
      "  MAE: 0.10\n",
      "  MSE: 0.03\n",
      "  RMSE: 0.18\n",
      "  R2: 0.02\n",
      "  Accuracy: 0.95\n",
      "  F1: 0.93\n",
      "  Precision: 0.94\n",
      "  Recall: 0.95\n",
      "\n",
      "Overall Metrics (Average and STD):\n",
      "  MAE - Average: 0.30, STD: 0.24\n",
      "  MSE - Average: 0.27, STD: 0.36\n",
      "  RMSE - Average: 0.43, STD: 0.29\n",
      "  R2 - Average: 0.06, STD: 0.03\n",
      "  Accuracy - Average: 0.83, STD: 0.14\n",
      "  F1 - Average: 0.79, STD: 0.14\n",
      "  Precision - Average: 0.82, STD: 0.13\n",
      "  Recall - Average: 0.83, STD: 0.14\n",
      "\n",
      "=== CatBoost ===\n",
      "\n",
      "Sentiment Metrics:\n",
      "  MAE: 0.79\n",
      "  MSE: 1.07\n",
      "  RMSE: 1.03\n",
      "  R2: 0.12\n",
      "  Accuracy: 0.63\n",
      "  F1: 0.58\n",
      "  Precision: 0.61\n",
      "  Recall: 0.63\n",
      "\n",
      "Happy Metrics:\n",
      "  MAE: 0.46\n",
      "  MSE: 0.35\n",
      "  RMSE: 0.59\n",
      "  R2: 0.13\n",
      "  Accuracy: 0.62\n",
      "  F1: 0.63\n",
      "  Precision: 0.65\n",
      "  Recall: 0.62\n",
      "\n",
      "Sad Metrics:\n",
      "  MAE: 0.23\n",
      "  MSE: 0.10\n",
      "  RMSE: 0.32\n",
      "  R2: 0.08\n",
      "  Accuracy: 0.86\n",
      "  F1: 0.80\n",
      "  Precision: 0.83\n",
      "  Recall: 0.86\n",
      "\n",
      "Anger Metrics:\n",
      "  MAE: 0.22\n",
      "  MSE: 0.11\n",
      "  RMSE: 0.34\n",
      "  R2: 0.10\n",
      "  Accuracy: 0.88\n",
      "  F1: 0.83\n",
      "  Precision: 0.86\n",
      "  Recall: 0.88\n",
      "\n",
      "Surprise Metrics:\n",
      "  MAE: 0.09\n",
      "  MSE: 0.03\n",
      "  RMSE: 0.17\n",
      "  R2: 0.03\n",
      "  Accuracy: 0.97\n",
      "  F1: 0.95\n",
      "  Precision: 0.95\n",
      "  Recall: 0.97\n",
      "\n",
      "Disgust Metrics:\n",
      "  MAE: 0.18\n",
      "  MSE: 0.09\n",
      "  RMSE: 0.30\n",
      "  R2: 0.11\n",
      "  Accuracy: 0.91\n",
      "  F1: 0.88\n",
      "  Precision: 0.89\n",
      "  Recall: 0.91\n",
      "\n",
      "Fear Metrics:\n",
      "  MAE: 0.10\n",
      "  MSE: 0.03\n",
      "  RMSE: 0.18\n",
      "  R2: 0.04\n",
      "  Accuracy: 0.95\n",
      "  F1: 0.93\n",
      "  Precision: 0.95\n",
      "  Recall: 0.95\n",
      "\n",
      "Overall Metrics (Average and STD):\n",
      "  MAE - Average: 0.30, STD: 0.23\n",
      "  MSE - Average: 0.26, STD: 0.35\n",
      "  RMSE - Average: 0.42, STD: 0.28\n",
      "  R2 - Average: 0.08, STD: 0.03\n",
      "  Accuracy - Average: 0.83, STD: 0.14\n",
      "  F1 - Average: 0.80, STD: 0.13\n",
      "  Precision - Average: 0.82, STD: 0.13\n",
      "  Recall - Average: 0.83, STD: 0.14\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error, mean_squared_error, r2_score,\n",
    "    accuracy_score, f1_score, precision_score, recall_score\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# Assuming X_train, y_train, X_test, y_test are already defined\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define output names\n",
    "output_names = ['Sentiment', 'Happy', 'Sad', 'Anger', 'Surprise', 'Disgust', 'Fear']\n",
    "\n",
    "# Classification thresholds for each output\n",
    "def classify_output(y, threshold=0.5):\n",
    "    \"\"\"Classify outputs based on a simple threshold.\"\"\"\n",
    "    return (y > threshold).astype(int)\n",
    "\n",
    "# List of boosting algorithms to evaluate\n",
    "models = {\n",
    "    \"AdaBoost\": AdaBoostRegressor(),\n",
    "    \"XGBoost\": XGBRegressor(objective='reg:squarederror', tree_method='gpu_hist', verbosity=1),\n",
    "    \"LightGBM\": LGBMRegressor(verbose=1),\n",
    "    \"CatBoost\": CatBoostRegressor(verbose=1)\n",
    "}\n",
    "\n",
    "# Function to train and evaluate a single output\n",
    "def train_evaluate_output(output_name, model, X_train, X_test, y_train, y_test):\n",
    "    y_train_output = y_train.iloc[:, output_names.index(output_name)]\n",
    "    y_test_output = y_test.iloc[:, output_names.index(output_name)]\n",
    "    \n",
    "    # Train the model\n",
    "    model.fit(X_train, y_train_output)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred_output = model.predict(X_test)\n",
    "    \n",
    "    # Regression Metrics\n",
    "    mae = mean_absolute_error(y_test_output, y_pred_output)\n",
    "    mse = mean_squared_error(y_test_output, y_pred_output)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test_output, y_pred_output)\n",
    "    \n",
    "    # Classification Metrics\n",
    "    y_test_class = classify_output(y_test_output)\n",
    "    y_pred_class = classify_output(y_pred_output)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test_class, y_pred_class)\n",
    "    f1 = f1_score(y_test_class, y_pred_class, average='weighted')\n",
    "    precision = precision_score(y_test_class, y_pred_class, average='weighted')\n",
    "    recall = recall_score(y_test_class, y_pred_class, average='weighted')\n",
    "    \n",
    "    return {\n",
    "        \"Output\": output_name,\n",
    "        \"MAE\": mae, \"MSE\": mse, \"RMSE\": rmse, \"R2\": r2,\n",
    "        \"Accuracy\": accuracy, \"F1\": f1, \"Precision\": precision, \"Recall\": recall\n",
    "    }\n",
    "\n",
    "# Evaluate each model\n",
    "for model_name, base_model in models.items():\n",
    "    print(f\"\\n=== {model_name} ===\")\n",
    "    \n",
    "    # Train and evaluate in parallel for all outputs\n",
    "    results = Parallel(n_jobs=2)(delayed(train_evaluate_output)(\n",
    "        output_name, base_model, X_train_scaled, X_test_scaled, y_train, y_test\n",
    "    ) for output_name in output_names)\n",
    "    \n",
    "    # Gather metrics\n",
    "    metrics = {output[\"Output\"]: output for output in results}\n",
    "    \n",
    "    # Compute overall average and STD for all metrics\n",
    "    avg_metrics = {key: np.mean([metrics[output][key] for output in output_names]) \n",
    "                   for key in [\"MAE\", \"MSE\", \"RMSE\", \"R2\", \"Accuracy\", \"F1\", \"Precision\", \"Recall\"]}\n",
    "    std_metrics = {key: np.std([metrics[output][key] for output in output_names]) \n",
    "                   for key in [\"MAE\", \"MSE\", \"RMSE\", \"R2\", \"Accuracy\", \"F1\", \"Precision\", \"Recall\"]}\n",
    "    \n",
    "    # Print results\n",
    "    for output_name, output_metrics in metrics.items():\n",
    "        print(f\"\\n{output_name} Metrics:\")\n",
    "        for metric, value in output_metrics.items():\n",
    "            if metric != \"Output\":\n",
    "                print(f\"  {metric}: {value:.2f}\")\n",
    "    \n",
    "    print(\"\\nOverall Metrics (Average and STD):\")\n",
    "    for metric_name in avg_metrics.keys():\n",
    "        print(f\"  {metric_name} - Average: {avg_metrics[metric_name]:.2f}, STD: {std_metrics[metric_name]:.2f}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "name": "",
   "version": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
